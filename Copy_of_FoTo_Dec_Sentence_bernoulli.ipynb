{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "owtL4QR288GX",
        "Ehb8Jqe_Uf9J",
        "uuMpIj0Q7i7D",
        "nEfu6UC2Bqpm",
        "_3Ol7v77LCUK",
        "K0zQCuyY_kaq",
        "OHeUvin1UYy2",
        "tkoX5Yna0xYk",
        "MvJelmXZUlHy",
        "jCrmPj6uhZM4",
        "fYuPQevRdsEa",
        "YlpOWN_F1V5l",
        "GD5DxBd71eqd",
        "vFRHWpuwBmWn"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanujsriv/_topic_models/blob/FoTo/Copy_of_FoTo_Dec_Sentence_bernoulli.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PtRbasWGVvr"
      },
      "source": [
        "# **Download Preprocessed Data (Sentences)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4XlLYFYSLYu"
      },
      "source": [
        "############################ BBC #########################################\n",
        "!wget https://www.dropbox.com/s/2m1gbuvk1lz151j/data_bbc.zip\n",
        "\n",
        "## 64 batch size\n",
        "!wget https://www.dropbox.com/s/suivwmax9kmpu6r/n_s_v_dict_bbc_64.pkl\n",
        "!wget https://www.dropbox.com/s/kqpunihs8hgfzzm/all_indices_bbc_64.pkl\n",
        "########################### BBC ##########################################\n",
        "\n",
        "\n",
        "########################### 20News #######################################\n",
        "\n",
        "###-----\n",
        "# !wget https://www.dropbox.com/s/lnk001gexy74b0l/data.zip\n",
        "# !wget https://www.dropbox.com/s/n2iy4ooviyteii4/doc_sentences.pkl\n",
        "\n",
        "### 64 batch size\n",
        "# !wget https://www.dropbox.com/s/3kb4zazcailqqy2/n_s_v_dict_64_id_14.pkl\n",
        "# !wget https://www.dropbox.com/s/t5mxav9ytbzcci7/all_indices_id_14.pkl\n",
        "###-----\n",
        "\n",
        "\n",
        "## 32 batch size\n",
        "# !wget https://www.dropbox.com/s/2gaodary4smyiml/all_indices_id_12.pkl\n",
        "# !wget https://www.dropbox.com/s/y5mqy7mxzvimbde/n_s_v_dict_32_id_12.pkl\n",
        "\n",
        "## 128 batch size\n",
        "# !wget https://www.dropbox.com/s/jzyma764jyrs5we/n_s_v_dict_128_id_13.pkl\n",
        "# !wget https://www.dropbox.com/s/8lja1ynyuvc0sff/all_indices_id_13.pkl\n",
        "########################### 20News #######################################"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owtL4QR288GX"
      },
      "source": [
        "#**unzip**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNoCND_g-cPw"
      },
      "source": [
        "import os\n",
        "\n",
        "def unzip_bbc():\n",
        "  os.system('unzip data_bbc.zip')\n",
        "\n",
        "def unzip_20News():\n",
        "  os.system('unzip data.zip')\n",
        "  os.system('unzip train_vec_non_zeros.zip')\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UH9i4xMWSP9c"
      },
      "source": [
        "unzip_bbc()\n",
        "# unzip_20News()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ehb8Jqe_Uf9J"
      },
      "source": [
        "#**# 0. Just Run these..**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "gn9JFNO4qjuf"
      },
      "source": [
        "#@title Imports\n",
        "# from sympy.stats import RaisedCosine, density\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "import re\n",
        "from matplotlib import pyplot as plt\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "import numpy as np\n",
        "import collections\n",
        "import torch.optim as optim\n",
        "# from utils import get_topwords, plot_fig\n",
        "# from plsv_vae import PlsvVAE\n",
        "# import data_preprocessing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "import sklearn\n",
        "import re\n",
        "import string\n",
        "from numpy import random\n",
        "# from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.datasets import fetch_rcv1\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "EivGqJ7vBoAo"
      },
      "source": [
        "#@title function : load / save pickle_obj\n",
        "import pickle\n",
        "\n",
        "def save_obj(obj, name):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_mOuwdiw_RE",
        "cellView": "form"
      },
      "source": [
        "#@title get_keywords\n",
        "def get_keywords():\n",
        "  keywords = []\n",
        "  keywords_arxiv = ['molecular ','stimulation','liquid','fluid']\n",
        "\n",
        "  keywords_webkb = ['class','student','department','year']\n",
        "  # keywords_r52 = ['mutual','fund','market','money']\n",
        "\n",
        "  keywords_WoS = ['pediatric','protein','clone']\n",
        "  # keywords_20News_Reuters = ['oil','price','opec','bpd','barrel','saudi','production','mln','crude']\n",
        "\n",
        "  keywords_reuters = ['company', 'analyst', 'offer', 'pct', 'takeover', 'merger', 'record', 'dividend', 'pay', 'stock']\n",
        "  # keywords_reuters = ['stock', 'dividend', 'inc']\n",
        "\n",
        "  # keywords_20News = ['baseball','game','sport','win']\n",
        "  # keywords_20News = ['looking' ,'add', 'voice' ,'input', 'capability', 'user', 'interface']\n",
        "  # keywords_20News = ['sport', 'baseball', 'game','match']\n",
        "\n",
        "  keywords_20News = ['windows','mac','cpu','graphic' ,'disk']\n",
        "\n",
        "  keywords_bbc = ['minister','security','politics','government']\n",
        "\n",
        "\n",
        "  keywords = keywords_bbc\n",
        "\n",
        "  return keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uuMpIj0Q7i7D"
      },
      "source": [
        "#**1. Model, Training, Testing, Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-mhG9BmEXzm",
        "cellView": "form"
      },
      "source": [
        "# @title Data Loading functions..\n",
        "def load_bbc_sentences():\n",
        "  doc_preprocessed = load_obj('doc_preprocessed_nonzeroes')\n",
        "  doc_preprocessed_labels = load_obj(\"doc_preprocessed_nonzeroes_labels\")\n",
        "  embeddings = load_obj('embeddings')\n",
        "  doc_id_sent = load_obj('doc_id_sent_nonzeros')\n",
        "  sen_preprocessed = load_obj('sen_preprocessed_nonzeroes')\n",
        "  train_vec = load_obj('train_vec_non_zeros')\n",
        "  vocab = load_obj('vocab')\n",
        "  all_rscores = None\n",
        "  return doc_preprocessed,doc_preprocessed_labels,embeddings,doc_id_sent,sen_preprocessed,train_vec,vocab,all_rscores,load_bbc_sentences.__name__\n",
        "\n",
        "\n",
        "def load_20News_sentences():\n",
        "  doc_preprocessed = load_obj('doc_preprocessed_nonzeroes')\n",
        "  doc_preprocessed_labels = load_obj(\"doc_preprocessed_nonzeroes_labels\")\n",
        "  embeddings = load_obj('embeddings_20news')\n",
        "  doc_id_sent = load_obj('doc_id_sent_nonzeros')\n",
        "  sen_preprocessed = load_obj('sen_preprocessed_nonzeroes')\n",
        "  train_vec = load_obj('train_vec_non_zeros')\n",
        "  vocab = load_obj('vocab')\n",
        "  all_rscores = load_obj('all_rscores')\n",
        "  return doc_preprocessed,doc_preprocessed_labels,embeddings,doc_id_sent,sen_preprocessed,train_vec,vocab,all_rscores,load_20News_sentences.__name__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MN4t01dDLCs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8210ed92-8c39-4d40-a048-f12d796b7b47"
      },
      "source": [
        "# ##### Data loading #####\n",
        "# loaded_data = load_20News_sentences\n",
        "loaded_data = load_bbc_sentences\n",
        "\n",
        "##########################\n",
        "\n",
        "doc_preprocessed,doc_preprocessed_labels,embeddings,doc_id_sent,sen_preprocessed,train_vec,vocab,all_rscores, name = loaded_data()\n",
        "print(name,len(doc_preprocessed_labels),len(doc_preprocessed),len(embeddings),len(doc_id_sent),len(sen_preprocessed))\n",
        "print(len(doc_preprocessed),max(doc_id_sent)+1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "load_bbc_sentences 2225 2225 5000 33571 33571\n",
            "2225 2225\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ilWxWKAROUN7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70b45f16-4f1b-4bf4-bfa0-0f547126e3ce"
      },
      "source": [
        "c=0\n",
        "for d in doc_preprocessed:\n",
        "  if 'windows' in d or 'mac' in d or 'cpu' in d or 'graphic' in d or 'disk' in d:\n",
        "    c=c+1\n",
        "c"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "192"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Eed89iETbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bccc8f1-efa1-46b4-8e8a-923381708f4d"
      },
      "source": [
        "def most_frequent(List):\n",
        "    return max(set(List), key = List.count)\n",
        "most_freq = most_frequent(doc_id_sent)\n",
        "max_sent = doc_id_sent.count(most_freq)\n",
        "most_freq , max_sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1185, 186)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aE8GgAEoUnG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173ff1bf-92ab-4d44-aa02-bd805d7f7b12"
      },
      "source": [
        "k=1221\n",
        "print(doc_preprocessed[k])\n",
        "print(doc_preprocessed_labels[k])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " prime minister playing politics security howard ha doubt prime minister claim ramming parliament controversial antiterror measure proper debate tory prime minister playing fear card tough general election tony blair issue tory soft terrorism earth prime minister simply tory offer extend existing power temporarily allow proper parliamentary debate law demanded prime minister claim clearest indication tory playing politics issue attempting score cheap political point parliament opposition proposed law principle case delaying decision debate belief blair tory spotting opportunity embarrass defeat government national security liberal democrat leader charles kennedy avoided suggesting wa playing politics issue preferred state issue card government instinct wa habit nowadays prime minister wa le rough kennedy howard prefers exasperated tone suggesting belief lib dems missed point apart wa electioneering usual question prime minister derby north bob asked carry excellent policy pouring resource school birmingham sion simon tory shower general election prime minister blushed wa appropriate place election day stammered doubt announcement day announcement coming week april election big money common simple fact playing politics moment\n",
            "politics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf2NCulM_QmX"
      },
      "source": [
        "doc_sentences = load_obj('doc_sentences')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEfu6UC2Bqpm"
      },
      "source": [
        "#**2. Model hyper-parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXW7EAT4gdz9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b074135-6b30-43f2-dcc8-cc50631a5ab8"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "train_vec = np.array(train_vec)\n",
        "#tensor_train_w = torch.from_numpy(train_vec)\n",
        "train_label = np.asarray(doc_preprocessed_labels)\n",
        "id_vocab = dict(map(reversed, vocab.items()))\n",
        "num_voc = len(id_vocab)\n",
        "num_coordinate = 2\n",
        "bs = 64\n",
        "\n",
        "# bs = 128\n",
        "# bs = 10\n",
        "# bs = 5\n",
        "\n",
        "en1_units_x = 100\n",
        "en2_units_x = 100\n",
        "\n",
        "num_input = train_vec[0].shape[0]\n",
        "variance_x = 1\n",
        "learning_rate = 0.002\n",
        "beta1 = 0.99\n",
        "beta2 = 0.999\n",
        "drop_rate = 0.6\n",
        "num_topic = 20\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pVbMcbFDpAX2"
      },
      "source": [
        "empty_sentence = np.zeros(train_vec.shape[1],dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nnkLeGKB6o4"
      },
      "source": [
        "def get_mem_size(a):\n",
        "  return 'Mem Size: '+str(a.element_size()*a.nelement() /(1024**3))+' GB'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kc3vGKGCIcFe"
      },
      "source": [
        "#**3. Bernoulli v2 - Avg. Fraction of Sentences**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwC_h6w1InM8"
      },
      "source": [
        "def padarray(A, size,criteria):\n",
        "    A = list(A)\n",
        "    if criteria=='top':\n",
        "      A[::-1].sort()\n",
        "    elif criteria=='first':\n",
        "      pass\n",
        "    t = size - len(A)\n",
        "    if t<=0:\n",
        "      return A[:size]\n",
        "    else:\n",
        "      for _ in range(t):\n",
        "        A.append(0)\n",
        "      return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8QuFllLJWal"
      },
      "source": [
        "sen_kw = []\n",
        "kw = np.array([])\n",
        "\n",
        "keys  = get_keywords()\n",
        "for s in sen_preprocessed:\n",
        "  key_indicator = 0\n",
        "  for k in keys:\n",
        "    # if k in s:\n",
        "    if re.search(r'\\b' + k + r'\\b', s):\n",
        "      key_indicator = 1\n",
        "      sen_kw.append(key_indicator)\n",
        "      break\n",
        "  if key_indicator == 0:\n",
        "    sen_kw.append(key_indicator)\n",
        "sen_kw =np.array(sen_kw)\n",
        "score = [sen_kw[i] for i in doc_sentences]\n",
        "\n",
        "for i in range(len(score)):\n",
        "  kw=np.append(kw,score[i].mean())\n",
        "kw=torch.tensor(kw)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UEuP0350zRZs"
      },
      "source": [
        "for i in range(len(score)):\n",
        "  score[i] = padarray(score[i],50,'first')\n",
        "key_indicator = torch.tensor(np.array(score))\n",
        "key_indicator = key_indicator.unsqueeze(2).expand(kw.shape[0],50,1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaWGCCepd_zi",
        "outputId": "591fdbc6-1fdb-4df0-a4a9-a530edf5559e"
      },
      "source": [
        "key_indicator[-1]\n",
        "# doc_sentences[-1],np.nonzero(sen_kw)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0],\n",
              "        [0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDcQ40D0JJqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d451dace-0276-4514-ef46-2b92428d5774"
      },
      "source": [
        "k=1221\n",
        "doc_sentences[k],sen_preprocessed[min(doc_sentences[k]):max(doc_sentences[k])+1],doc_preprocessed[k]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([16710,\n",
              "  16711,\n",
              "  16712,\n",
              "  16713,\n",
              "  16714,\n",
              "  16715,\n",
              "  16716,\n",
              "  16717,\n",
              "  16718,\n",
              "  16719,\n",
              "  16720,\n",
              "  16721,\n",
              "  16722,\n",
              "  16723,\n",
              "  16724],\n",
              " ['prime minister playing politics security howard ha doubt prime minister claim ramming parliament controversial antiterror measure proper debate',\n",
              "  'tory prime minister playing fear card tough general election tony blair issue tory soft terrorism',\n",
              "  'earth prime minister simply tory offer extend existing power temporarily allow proper parliamentary debate law demanded',\n",
              "  'prime minister claim clearest indication tory playing politics issue attempting score cheap political point parliament',\n",
              "  'opposition proposed law principle case delaying decision debate belief blair tory spotting opportunity embarrass defeat government',\n",
              "  'national security',\n",
              "  'liberal democrat leader charles kennedy avoided suggesting wa playing politics issue',\n",
              "  'preferred state issue card government instinct wa habit nowadays prime minister wa le rough kennedy howard prefers exasperated tone suggesting belief lib dems missed point',\n",
              "  'apart wa electioneering usual',\n",
              "  'question prime minister derby north bob asked carry excellent policy pouring resource school',\n",
              "  'birmingham sion simon tory shower general election',\n",
              "  'prime minister blushed',\n",
              "  'wa appropriate place election day stammered',\n",
              "  'doubt announcement day announcement coming week april election big money common',\n",
              "  'simple fact playing politics moment'],\n",
              " ' prime minister playing politics security howard ha doubt prime minister claim ramming parliament controversial antiterror measure proper debate tory prime minister playing fear card tough general election tony blair issue tory soft terrorism earth prime minister simply tory offer extend existing power temporarily allow proper parliamentary debate law demanded prime minister claim clearest indication tory playing politics issue attempting score cheap political point parliament opposition proposed law principle case delaying decision debate belief blair tory spotting opportunity embarrass defeat government national security liberal democrat leader charles kennedy avoided suggesting wa playing politics issue preferred state issue card government instinct wa habit nowadays prime minister wa le rough kennedy howard prefers exasperated tone suggesting belief lib dems missed point apart wa electioneering usual question prime minister derby north bob asked carry excellent policy pouring resource school birmingham sion simon tory shower general election prime minister blushed wa appropriate place election day stammered doubt announcement day announcement coming week april election big money common simple fact playing politics moment')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O9KOugSOF6zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f541356-0e92-4e8b-b90a-312f283c9a74"
      },
      "source": [
        "torch.sort(kw,descending=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.sort(values=tensor([0.7500, 0.7500, 0.7333,  ..., 0.0000, 0.0000, 0.0000],\n",
              "       dtype=torch.float64), indices=tensor([1131, 1238, 1221,  ...,  513,   84,   85]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFLvcUu84qjo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d8ec702-acee-4082-c4d9-5641b87fe58e"
      },
      "source": [
        "kws=kw.unsqueeze(1).unsqueeze(1).expand(kw.shape[0],50,1)\n",
        "kws.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2225, 50, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3Ol7v77LCUK"
      },
      "source": [
        "# **4. all_indices, sparse_matrix, cached_input** *(Just Run Once)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "srWCgayAir0V"
      },
      "source": [
        "#@title sparse matrix : temp code\n",
        "\n",
        "# num_doc = max(doc_id_sent)+1\n",
        "# s_v_num_nonzeros = np.count_nonzero(train_vec)\n",
        "# s_v_i = torch.zeros((3, s_v_num_nonzeros),dtype=torch.long)\n",
        "# s_v_float = torch.zeros(s_v_num_nonzeros)\n",
        "# count = 0\n",
        "\n",
        "# for i,j in enumerate(doc_sentences):\n",
        "#   # print(i,count)\n",
        "#   s_v_i[0][count] = i\n",
        "#   for k,l in enumerate(j):\n",
        "#     s_v_i[1][count] = k\n",
        "#     for m,n in enumerate(train_vec[l]):\n",
        "#       if(n!=0):\n",
        "#         s_v_i[2][count] = m\n",
        "#         s_v_float[count]= torch.tensor(n)\n",
        "#         count = count + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24rTeeVwqgRY"
      },
      "source": [
        "# # bs=64\n",
        "# all_indices = torch.randperm(max(doc_id_sent)+1).split(bs)\n",
        "all_indices = load_obj('all_indices_bbc_64')\n",
        "n_s_v_dict = load_obj('n_s_v_dict_bbc_64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiBWM0nXub3r",
        "cellView": "form"
      },
      "source": [
        "#@title (Not Using) create nsv on the fly (takes a lot of time)\n",
        "# doc_sent_a = np.array(doc_sentences)\n",
        "\n",
        "\n",
        "# def stack_empty_sentences(A,size):\n",
        "#    t = size - A.shape[0]\n",
        "#    if t<=0:\n",
        "#      return A[:size]\n",
        "#    else:\n",
        "#       empty_sentences = np.zeros((t,train_vec.shape[1]),dtype=np.float32)\n",
        "#       A=np.vstack((A,empty_sentences))\n",
        "#       return A\n",
        "\n",
        "# for d,batch_ndx in enumerate(all_indices):\n",
        "#   current_batch = []\n",
        "#   current_doc_batch = doc_sent_a[batch_ndx]\n",
        "#   for ndx in current_doc_batch:\n",
        "#     # print(\"Index:\\n\\n\",ndx,stack_empty_sentences(train_vec[ndx],50).shape)\n",
        "#     current_batch.append(stack_empty_sentences(train_vec[ndx],50))\n",
        "\n",
        "## Paste this after for loop for batch\n",
        "\n",
        "  #####################################################################\n",
        "        # current_batch = []\n",
        "        # current_doc_batch = doc_sent_a[batch_ndx]\n",
        "\n",
        "        # for ndx in current_doc_batch:\n",
        "        #     current_batch.append(stack_empty_sentences(train_vec[ndx],50))\n",
        "        # input_nsv = torch.tensor(current_batch).to(device)\n",
        "        ######################################################################\n",
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3W4nQ7h3Jzt",
        "cellView": "form"
      },
      "source": [
        "#@title Sparse maatrix : if all_indices change run this..\n",
        "\n",
        "# # from collections import OrderedDict\n",
        "# # n_s_v_dict = OrderedDict()\n",
        "\n",
        "# # # Sparse Matrix for Batch Size : 64\n",
        "\n",
        "# bs = 64\n",
        "# sent = 50\n",
        "# n_s_v_dict = {}\n",
        "\n",
        "# for d,batch_ndx in enumerate(all_indices):\n",
        "#   count = 0\n",
        "#   s_v_num_nonzeros = 0\n",
        "\n",
        "#   for j,i in enumerate(batch_ndx):\n",
        "#     if(len(doc_sentences[i.item()])>sent):\n",
        "#       s_v = train_vec[doc_sentences[i.item()][0:sent]]\n",
        "#     else:\n",
        "#       s_v = train_vec[doc_sentences[i.item()]]\n",
        "#     s_v_num_nonzeros = s_v_num_nonzeros + np.count_nonzero(s_v)\n",
        "#   s_v_i = torch.zeros((3, s_v_num_nonzeros),dtype=torch.long)\n",
        "#   s_v_float = torch.zeros(s_v_num_nonzeros)\n",
        "\n",
        "#   for j,i in enumerate(batch_ndx):\n",
        "#     ss = doc_sentences[i.item()]\n",
        "#     for k,l in enumerate(ss):\n",
        "#       if k>=sent: break\n",
        "#       nz = np.nonzero(train_vec[l])\n",
        "#       for m in nz[0]:\n",
        "#         s_v_i[0][count] = j\n",
        "#         s_v_i[1][count] = k\n",
        "#         s_v_i[2][count] = m\n",
        "#         s_v_float[count] = torch.tensor(train_vec[l][m])\n",
        "#         #if(torch.tensor(train_vec[l][m])== torch.tensor(0.0)): print('*********************')\n",
        "#         count = count + 1\n",
        "#   n_s_v_dict[d] = torch.sparse.FloatTensor(s_v_i, s_v_float, torch.Size([batch_ndx.shape[0],50,num_voc]))\n",
        "# #   ##\n",
        "\n",
        "# #   # t = all_indices[d][0]\n",
        "# #   #print(train_vec[doc_sentences[t.item()][0]].shape)\n",
        "# #   # t1 = np.nonzero(train_vec[doc_sentences[t.item()][0]])\n",
        "# #   # if(train_vec[doc_sentences[t.item()][0]][t1[0][0]]!=n_s_v_dict[d].to_dense()[0][0][t1[0][0]]): print(train_vec[0][t1[0][0]], n_s_v_dict[d].to_dense()[0][0][t1[0][0]])\n",
        "# #   gc.collect()\n",
        "\n",
        "# for i in range(d+1):\n",
        "#   if n_s_v_dict[i].size()[0] != bs:\n",
        "#    print(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CdqLpSrC0fc"
      },
      "source": [
        "# save_obj(n_s_v_dict,'n_s_v_dict_bbc_64')\n",
        "# save_obj(all_indices,'all_indices_bbc_64')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZeXRQC0UgXQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc1d6e14-e79e-4a7d-eecf-e373755eb005"
      },
      "source": [
        "# del cached_nsv\n",
        "# del cached_inputw\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XtwYRIwzXsK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "778c2b55-6165-43f0-95f4-8c40d978554a"
      },
      "source": [
        "# del cached_nsv,cached_inputw\n",
        "cached_inputw = []\n",
        "# cached_nsv= []\n",
        "\n",
        "gc.collect()\n",
        "for d,batch_ndx in enumerate(all_indices):\n",
        "  # if(d<=300):\n",
        "  #   cached_nsv.append(n_s_v_dict[d].to_dense())\n",
        "  cached_inputw.append(n_s_v_dict[d].to_dense().sum(dim=1))\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtRrwY7L-oRL"
      },
      "source": [
        "# **Current Model**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20SZS3Q4FVzq"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.nn import Parameter\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "pi = 3.1415927410125732\n",
        "\n",
        "# def bernoulli_log_likelihood(x,mu):\n",
        "#   return  (x * torch.log(mu)) * ( (1-x)*torch.log(1-mu) )\n",
        "\n",
        "# def log_gaussian_binomial(mu,N):\n",
        "#   mean = mu * N\n",
        "#   var = (N * mu * (1-mu)) ** 0.5\n",
        "#   ret = -0.5 * ( (x-mean)/var)**2 - torch.log(var*(2*pi)**0.5)\n",
        "#   return ret\n",
        "\n",
        "#phi\n",
        "def gaussian(alpha): return -0.5*alpha\n",
        "def inverse_multi_quadric(alpha): return -0.5*torch.log(torch.ones_like(alpha) + alpha)\n",
        "def inverse_quadratic(alpha): return -torch.log(torch.ones_like(alpha) + alpha)\n",
        "\n",
        "class FoTo(nn.Module):\n",
        "    def __init__(self, num_input, en1_units_x, en2_units_x, num_coordinate, num_topic, drop_rate, variance_x, bs, distance=\"gaussian\"):\n",
        "        super(FoTo, self).__init__()\n",
        "        self.num_input, self.num_coordinate, self.num_topic, self.variance_x, self.bs\\\n",
        "            = num_input, num_coordinate, num_topic, variance_x, bs\n",
        "\n",
        "        # encoder\n",
        "        self.en1_fc     = nn.Linear(num_input, en1_units_x)             # V -> 100 # nxV->(vxh1)->nxh1;\n",
        "        self.en2_fc     = nn.Linear(en1_units_x, en2_units_x)           # 100  -> 100\n",
        "        self.en2_drop   = nn.Dropout(drop_rate)\n",
        "        self.mean_fc    = nn.Linear(en2_units_x, num_coordinate)        # 100  -> 2\n",
        "        self.mean_bn    = nn.BatchNorm1d(num_coordinate)                # bn for mean\n",
        "        self.logvar_fc  = nn.Linear(en2_units_x, num_coordinate)        # 100  -> 2\n",
        "        self.logvar_bn  = nn.BatchNorm1d(num_coordinate)                # bn for logvar\n",
        "\n",
        "        # RBF\n",
        "        self.in_features = self.num_coordinate\n",
        "        self.out_features = self.num_topic\n",
        "        self.centres = nn.Parameter(torch.Tensor(self.out_features, self.in_features))\n",
        "        # self.query_center = nn.Parameter(torch.zeros(2,1))\n",
        "\n",
        "        if distance==\"gaussian\": self.basis_func = gaussian\n",
        "        if distance==\"inverse_quadratic\": self.basis_func = inverse_quadratic\n",
        "        if distance==\"inverse_multi_quadric\": self.basis_func = inverse_multi_quadric\n",
        "        self.init_parameters()\n",
        "\n",
        "        # decoder\n",
        "        self.decoder    = nn.Linear(self.num_topic, self.num_input)\n",
        "        self.decoder_bn = nn.BatchNorm1d(self.num_topic)                    # bn for decoder\n",
        "        self.decoder_phi_bn = nn.BatchNorm1d(num_coordinate)                # bn for phi decoder\n",
        "        self.decoder_x_bn = nn.BatchNorm1d(num_coordinate)                  # bn for x decoder\n",
        "\n",
        "        # prior mean and variance as constant buffers\n",
        "        prior_mean   = torch.Tensor(1, num_coordinate).fill_(0)\n",
        "        prior_var    = torch.Tensor(1, num_coordinate).fill_(variance_x)\n",
        "\n",
        "        self.prior_mean = nn.Parameter(prior_mean, requires_grad=False)\n",
        "        self.prior_var  = nn.Parameter(prior_var, requires_grad=False)\n",
        "        self.prior_logvar = nn.Parameter(prior_var.log(), requires_grad=False)\n",
        "\n",
        "    def init_parameters(self): nn.init.normal_(self.centres, 0, 0.01)\n",
        "\n",
        "    def encode(self, input_):\n",
        "        N = input_.size()[0]\n",
        "\n",
        "        en1 = F.softplus(self.en1_fc(input_))                           # en1_fc   output\n",
        "        en2 = F.softplus(self.en2_fc(en1))                              # encoder2 output\n",
        "        en2 = self.en2_drop(en2)\n",
        "\n",
        "        posterior_mean   = self.mean_bn(self.mean_fc(en2))              # posterior mean\n",
        "        posterior_logvar = self.logvar_bn(self.logvar_fc(en2))          # posterior log variance\n",
        "        posterior_var    = posterior_logvar.exp()\n",
        "\n",
        "        return en2, posterior_mean, posterior_logvar, posterior_var\n",
        "\n",
        "    def take_sample(self, input_, posterior_mean, posterior_var, prior_var):\n",
        "        # take sample\n",
        "        eps = input_.data.new().resize_as_(posterior_mean.data).normal_(std=1) # noise\n",
        "        # N x X\n",
        "        z = posterior_mean + posterior_var.sqrt() * eps                   # reparameterization\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "\n",
        "        # decode\n",
        "        N, *_ = z.size()\n",
        "        size = (N, self.out_features, self.in_features) # NxTx2\n",
        "        zx = self.decoder_x_bn(z).view(N, 1, self.num_coordinate) # Nx1xX\n",
        "        x = zx.expand(size)\n",
        "        c = self.decoder_phi_bn(self.centres).unsqueeze(0).expand(size)\n",
        "        d = (x-c).pow(2).sum(-1)\n",
        "        distances = self.basis_func(d) #NxK\n",
        "        zx_phi = torch.exp(distances - torch.logsumexp(distances, dim=-1, keepdim=True))\n",
        "\n",
        "        ######################################################\n",
        "        NS_size = (N,50)\n",
        "        TV_size = tuple(self.decoder.weight.T.size())\n",
        "\n",
        "        ### P(W|z) ||  N x S x T x V ###\n",
        "        W = F.softmax(self.decoder_bn(self.decoder.weight).transpose(1,0),dim=-1).unsqueeze(0).unsqueeze(0).expand(NS_size+TV_size)\n",
        "\n",
        "        ### P(z|x) ||  N x S x T ### (Theta)\n",
        "        Z = zx_phi.unsqueeze(1).expand(N,50,self.num_topic)\n",
        "\n",
        "        ### P(r|x,phi) || N x S ### (relv_status = {0,1})\n",
        "        theta_1= torch.narrow(Z,2,0,1) # theta_1 for N x S\n",
        "        pr = torch.cat((theta_1,1-theta_1),2) # (r=0 , r=1) #NxSx2\n",
        "        pr = pr.unsqueeze(2).expand(N,50,self.num_topic,2) # NxSxTx2\n",
        "\n",
        "        ######################################################\n",
        "\n",
        "        # recon_v = torch.mm(zx_phi, F.softmax(self.decoder_bn(self.decoder.weight).transpose(1,0), dim=-1))\n",
        "        return zx,zx_phi, d, c, W, Z,pr\n",
        "\n",
        "    def forward(self, input_,kI, kw, gpu_n_s_v, compute_loss=False):\n",
        "        fstart = time.time()\n",
        "        en2, posterior_mean, posterior_logvar, posterior_var = self.encode(input_)\n",
        "        z = self.take_sample(input_, posterior_mean, posterior_var, self.variance_x)\n",
        "\n",
        "        # decode\n",
        "        zx,zx_phi,d,c, W, Z,pr= self.decode(z)\n",
        "\n",
        "        if compute_loss:\n",
        "          lossN, NegativeLogL_RScore_mean, return_xKLD_mean = self.loss(input_, zx,zx_phi, posterior_mean, posterior_logvar, posterior_var, d, c, W, Z,pr, kI,kw, gpu_n_s_v)\n",
        "          return lossN, NegativeLogL_RScore_mean, return_xKLD_mean,time.time()-fstart\n",
        "        else:\n",
        "          return z, zx, zx_phi\n",
        "\n",
        "    def loss(self, input_, zx,zx_phi, posterior_mean, posterior_logvar, posterior_var, d, c, W, Z,pr, kI,kw, gpu_n_s_v, avg=True):\n",
        "\n",
        "        N = posterior_mean.shape[0]\n",
        "\n",
        "        prior_mean   = self.prior_mean.expand_as(posterior_mean)\n",
        "        prior_var    = self.prior_var.expand_as(posterior_mean)\n",
        "        prior_logvar = self.prior_logvar.expand_as(posterior_mean)\n",
        "\n",
        "        var_division    = posterior_var  / prior_var\n",
        "        diff            = posterior_mean - prior_mean\n",
        "        diff_term       = diff * diff / prior_var\n",
        "        logvar_division = prior_logvar - posterior_logvar\n",
        "\n",
        "        xKLD = 0.5 * ((var_division + diff_term + logvar_division).sum(-1) - self.num_coordinate)\n",
        "        xKLD_mean = xKLD.mean()\n",
        "\n",
        "        input_nstv = gpu_n_s_v.unsqueeze(2).expand((gpu_n_s_v.shape[0],50)+tuple(self.decoder.weight.T.shape))\n",
        "        smoothen = 1e-12\n",
        "\n",
        "        pkw = torch.cat((1-kw,kw),2) #NxSx2\n",
        "\n",
        "##########################################################################\n",
        "\n",
        "        pkw = pkw.unsqueeze(2).expand(N,50,self.num_topic,2) #NxSxTx2\n",
        "        KI = kI.unsqueeze(2).expand(N,50,self.num_topic,2) #NxSxTx2\n",
        "\n",
        "        p_kw_Obs = pkw ** KI\n",
        "        R_L = pr * p_kw_Obs # N x S x T x 2\n",
        "        W_I = (W**input_nstv).prod(-1) # N X S X T\n",
        "        R_Z =  R_L.sum(-1) * Z\n",
        "\n",
        "        NegativeLogL_RScore_mean = - (((W_I * R_Z).sum(-1) + smoothen).log()).mean()\n",
        "\n",
        "##########################################################################\n",
        "        # p_kw_Obs = pkw ** KI # N x S x 2\n",
        "        # p_r_kw = pr * p_kw_Obs # N x S x 2\n",
        "        # W_I = (W**input_nstv).prod(-1) # N X S X T\n",
        "\n",
        "        # NegativeLogL_RScore_mean = - (( (p_r_kw.sum(-1)) * (W_I * Z).sum(-1) + smoothen).log()).mean()\n",
        "\n",
        "        loss = xKLD_mean + NegativeLogL_RScore_mean\n",
        "        return loss, NegativeLogL_RScore_mean, xKLD_mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mF50pHtQdYag"
      },
      "source": [
        "kI.unsqueeze(2).expand(64,50,20,2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQltvxykSzN9"
      },
      "source": [
        "        # p(kw = 1|rs = 0) = 0\n",
        "        # p(kw = 1|rs = 1) == avg frac\n",
        "        # p(kw = 0|rs = 0) == 1\n",
        "        # p(kw = 0|rs = 1) == 1-avg frac\n",
        "\n",
        "p(r|x,phi): **NxSxTx2**\n",
        "\n",
        "p(z|x): NxT --> unsqueeze --> **NxSxT**\n",
        "\n",
        "p(w|z): TxV --> unsqueeze x 2 --> **NxSxTxV**\n",
        "\n",
        "input_w: NxSxV --> unsqueeze --> **NxSxTxV**\n",
        "\n",
        "log(sum ( *NxSxT* (R_L).sum(-1) * NxSxT (Z) * product((NxSxTxV)^input_w, dim=-1) NxSxT, dim = -1) ).sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTqfhWOvLKrJ"
      },
      "source": [
        "# **Train Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xiv54gv6-sqB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "fdfe733d-7126-4703-e2d5-1f51d0738ce7"
      },
      "source": [
        "model = FoTo(num_input, en1_units_x, en2_units_x, num_coordinate, num_topic, drop_rate, variance_x, bs, \"inverse_quadratic\")\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), learning_rate, betas=(beta1, beta2))\n",
        "epochs = 50\n",
        "x_arr,recon_arr = [],[]\n",
        "for epoch in range(epochs):\n",
        "    loss_u_epoch = 0.0\n",
        "    loss_xkl_epoch = 0.0\n",
        "    loss_epoch = 0.0\n",
        "    model.train()\n",
        "\n",
        "    for d,batch_ndx in enumerate(all_indices):\n",
        "        gpu_n_s_v = n_s_v_dict[d].to(device).to_dense()\n",
        "        # score_n_s = score_all_doc_s_n[batch_ndx].to(device)\n",
        "        input_w = cached_inputw[d].to(device)\n",
        "        kws_b = kws[batch_ndx].to(device)\n",
        "        kI = key_indicator[batch_ndx].to(device)\n",
        "        labels = train_label[batch_ndx]\n",
        "\n",
        "        (loss, loss_u, xkl_loss,forward_time) = model(input_w, kI,kws_b,gpu_n_s_v, compute_loss=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()             # backpror.step()            # update parameters\n",
        "\n",
        "        loss_u_epoch += loss_u.item()\n",
        "        loss_xkl_epoch += xkl_loss.item()\n",
        "\n",
        "    x_arr.append(loss_xkl_epoch)\n",
        "    recon_arr.append(loss_u_epoch)\n",
        "\n",
        "    if epoch % 1 == 0:\n",
        "        print('Epoch {}'.format(epoch))\n",
        "        print('recon_loss={}, KLD= {}'.format(loss_u_epoch, loss_xkl_epoch))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[0.0688, 0.0308, 0.0309,  ..., 0.1010, 0.0241, 0.0308],\n",
            "         [0.0688, 0.0308, 0.0309,  ..., 0.1010, 0.0241, 0.0308],\n",
            "         [0.0688, 0.0308, 0.0309,  ..., 0.1010, 0.0241, 0.0308],\n",
            "         ...,\n",
            "         [0.0688, 0.0308, 0.0309,  ..., 0.1010, 0.0241, 0.0308],\n",
            "         [0.0688, 0.0308, 0.0309,  ..., 0.1010, 0.0241, 0.0308],\n",
            "         [0.0688, 0.0308, 0.0309,  ..., 0.1010, 0.0241, 0.0308]],\n",
            "\n",
            "        [[0.0235, 0.0715, 0.0541,  ..., 0.0374, 0.1130, 0.0554],\n",
            "         [0.0235, 0.0715, 0.0541,  ..., 0.0374, 0.1130, 0.0554],\n",
            "         [0.0235, 0.0715, 0.0541,  ..., 0.0374, 0.1130, 0.0554],\n",
            "         ...,\n",
            "         [0.0235, 0.0715, 0.0541,  ..., 0.0374, 0.1130, 0.0554],\n",
            "         [0.0235, 0.0715, 0.0541,  ..., 0.0374, 0.1130, 0.0554],\n",
            "         [0.0235, 0.0715, 0.0541,  ..., 0.0374, 0.1130, 0.0554]],\n",
            "\n",
            "        [[0.0615, 0.0259, 0.0313,  ..., 0.0289, 0.0145, 0.0308],\n",
            "         [0.0615, 0.0259, 0.0313,  ..., 0.0289, 0.0145, 0.0308],\n",
            "         [0.0615, 0.0259, 0.0313,  ..., 0.0289, 0.0145, 0.0308],\n",
            "         ...,\n",
            "         [0.0615, 0.0259, 0.0313,  ..., 0.0289, 0.0145, 0.0308],\n",
            "         [0.0615, 0.0259, 0.0313,  ..., 0.0289, 0.0145, 0.0308],\n",
            "         [0.0615, 0.0259, 0.0313,  ..., 0.0289, 0.0145, 0.0308]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.1018, 0.0278, 0.0288,  ..., 0.0816, 0.0277, 0.0286],\n",
            "         [0.1018, 0.0278, 0.0288,  ..., 0.0816, 0.0277, 0.0286],\n",
            "         [0.1018, 0.0278, 0.0288,  ..., 0.0816, 0.0277, 0.0286],\n",
            "         ...,\n",
            "         [0.1018, 0.0278, 0.0288,  ..., 0.0816, 0.0277, 0.0286],\n",
            "         [0.1018, 0.0278, 0.0288,  ..., 0.0816, 0.0277, 0.0286],\n",
            "         [0.1018, 0.0278, 0.0288,  ..., 0.0816, 0.0277, 0.0286]],\n",
            "\n",
            "        [[0.1349, 0.0331, 0.0397,  ..., 0.0531, 0.0170, 0.0389],\n",
            "         [0.1349, 0.0331, 0.0397,  ..., 0.0531, 0.0170, 0.0389],\n",
            "         [0.1349, 0.0331, 0.0397,  ..., 0.0531, 0.0170, 0.0389],\n",
            "         ...,\n",
            "         [0.1349, 0.0331, 0.0397,  ..., 0.0531, 0.0170, 0.0389],\n",
            "         [0.1349, 0.0331, 0.0397,  ..., 0.0531, 0.0170, 0.0389],\n",
            "         [0.1349, 0.0331, 0.0397,  ..., 0.0531, 0.0170, 0.0389]],\n",
            "\n",
            "        [[0.0234, 0.0842, 0.0908,  ..., 0.0238, 0.0262, 0.0914],\n",
            "         [0.0234, 0.0842, 0.0908,  ..., 0.0238, 0.0262, 0.0914],\n",
            "         [0.0234, 0.0842, 0.0908,  ..., 0.0238, 0.0262, 0.0914],\n",
            "         ...,\n",
            "         [0.0234, 0.0842, 0.0908,  ..., 0.0238, 0.0262, 0.0914],\n",
            "         [0.0234, 0.0842, 0.0908,  ..., 0.0238, 0.0262, 0.0914],\n",
            "         [0.0234, 0.0842, 0.0908,  ..., 0.0238, 0.0262, 0.0914]]],\n",
            "       device='cuda:0', grad_fn=<ExpandBackward>)\n",
            "tensor([[[0.0688],\n",
            "         [0.0688],\n",
            "         [0.0688],\n",
            "         ...,\n",
            "         [0.0688],\n",
            "         [0.0688],\n",
            "         [0.0688]],\n",
            "\n",
            "        [[0.0235],\n",
            "         [0.0235],\n",
            "         [0.0235],\n",
            "         ...,\n",
            "         [0.0235],\n",
            "         [0.0235],\n",
            "         [0.0235]],\n",
            "\n",
            "        [[0.0615],\n",
            "         [0.0615],\n",
            "         [0.0615],\n",
            "         ...,\n",
            "         [0.0615],\n",
            "         [0.0615],\n",
            "         [0.0615]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[0.1018],\n",
            "         [0.1018],\n",
            "         [0.1018],\n",
            "         ...,\n",
            "         [0.1018],\n",
            "         [0.1018],\n",
            "         [0.1018]],\n",
            "\n",
            "        [[0.1349],\n",
            "         [0.1349],\n",
            "         [0.1349],\n",
            "         ...,\n",
            "         [0.1349],\n",
            "         [0.1349],\n",
            "         [0.1349]],\n",
            "\n",
            "        [[0.0234],\n",
            "         [0.0234],\n",
            "         [0.0234],\n",
            "         ...,\n",
            "         [0.0234],\n",
            "         [0.0234],\n",
            "         [0.0234]]], device='cuda:0', grad_fn=<SliceBackward>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-eb10573e0f0a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_ndx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_u\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxkl_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mforward_time\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkws_b\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgpu_n_s_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-49bf52599263>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_, kI, kw, gpu_n_s_v, compute_loss)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m           \u001b[0mlossN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNegativeLogL_RScore_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_xKLD_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mzx_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_logvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mposterior_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkI\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_n_s_v\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mlossN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNegativeLogL_RScore_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_xKLD_mean\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-96-49bf52599263>\u001b[0m in \u001b[0;36mloss\u001b[0;34m(self, input_, zx, zx_phi, posterior_mean, posterior_logvar, posterior_var, d, c, W, Z, pr, kI, kw, gpu_n_s_v, avg)\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0minput_nstv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_n_s_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpu_n_s_v\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0msmoothen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-12\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mxx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m         \u001b[0mpkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#NxSx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mpkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpkw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#NxSxTx2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'xx' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K0zQCuyY_kaq"
      },
      "source": [
        "# **Functions (Plot_loss, get_topwords, get_Z, get_Contour)** - *Run Once*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "IQs6On09Oj9I"
      },
      "source": [
        "#@title get_all_tensor_size\n",
        "def getall_tensor_size():\n",
        "  for obj in gc.get_objects():\n",
        "    try:\n",
        "        if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n",
        "            print(type(obj), obj.size(),get_mem_size(obj))\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9dbke4-9_Wy"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "def plot_loss(y,name):\n",
        "  figure = go.Figure()\n",
        "  figure.add_trace(go.Scatter(x=[i for i in range(1,epochs+1)], y=y,mode='lines',name=name))\n",
        "  figure.show(renderer='colab')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2dWYfSoAqaC"
      },
      "source": [
        "def get_topwords(beta, id_vocab):\n",
        "    topic_indx = 0\n",
        "    topwords_topic = []\n",
        "    for i in range(len(beta)):\n",
        "        topwords_topic.append( str(topic_indx)+\": \"+ \" \".join([id_vocab[j] for j in beta[i].argsort()[:-10 - 1:-1]]))\n",
        "        topic_indx+=1\n",
        "    return topwords_topic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2DrizcsH104"
      },
      "source": [
        "def get_Z(X,Y,query_center):\n",
        "  norms = torch.zeros(X.shape)\n",
        "  Z = torch.zeros(X.shape)\n",
        "\n",
        "  for i in range(X.shape[0]):\n",
        "    for j in range(X.shape[0]):\n",
        "      v = torch.tensor([X[i][j],Y[i][j]])\n",
        "\n",
        "      # norms[i][j] = torch.norm(v)\n",
        "      # Z[i][j]=torch.exp(-0.5 * (torch.pow(norms[i][j],2))/mu_div)\n",
        "\n",
        "      norms[i][j] = (v-query_center.T).pow(2).sum(-1)\n",
        "      Z[i][j]=torch.exp(-0.5 * norms[i][j]/mu_div)\n",
        "  return Z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRLLNAyXZx81"
      },
      "source": [
        "def get_Contour(ax,x_list,query_center):\n",
        "  xlist = np.linspace(-50, 50, 100)\n",
        "  ylist = np.linspace(-50, 50, 100)\n",
        "  X, Y = np.meshgrid(xlist, ylist)\n",
        "  Z = get_Z(X,Y,query_center)\n",
        "  levels = np.arange(0,1,0.1)\n",
        "  cp = ax.contour(X, Y, Z, levels=levels)\n",
        "  ax.clabel(cp, inline=1, fontsize=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvSQQ9csm8Uq"
      },
      "source": [
        "import seaborn as sb\n",
        "\n",
        "def plot_fig(zx, labels_list, zphi, query_center,lim,contour='No'):\n",
        "    labels = []\n",
        "    for i in range(len(labels_list)):\n",
        "        labels.append('C'+str(labels_list[i]))\n",
        "    fig, ax = plt.subplots( figsize=(20, 20))\n",
        "    if contour=='yes':\n",
        "       get_Contour(ax,zx)\n",
        "\n",
        "    sb.scatterplot(ax=ax,x=zx[:,0],y=zx[:,1],hue=labels_list,alpha=0.8,palette='deep')\n",
        "    ax.set(ylim=lim)\n",
        "    ax.set(xlim=lim)\n",
        "\n",
        "    # ax.scatter(zx[:,0], zx[:,1], alpha=0.8, c=labels, facecolors='none', s=8)\n",
        "    # for d in range(len(labels_list)):\n",
        "    #  score = rounded_normalized_all_rscores[doc_ids[d]].item()\n",
        "    #  if(score>0.7 and score<0.9):\n",
        "    #   ax.text(zx[d,0],zx[d,1], str(round(score, 3) ) )\n",
        "\n",
        "    # ax.text(query_center[0],query_center[1], 'X' ,c='black')\n",
        "    # ax.text(0,0, 'X' ,c='black')\n",
        "    ax.scatter(zphi[:, 0], zphi[:, 1], alpha=1.0,  edgecolors='black', facecolors='none', s=30)\n",
        "\n",
        "    for indx, topic in enumerate(zphi):\n",
        "        ax.text(zphi[indx, 0], zphi[indx, 1], 'topic'+str(indx))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Z4WtR3DBBij"
      },
      "source": [
        "# **Plots, Topics & Visualization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tk1NHh-uEPDU"
      },
      "source": [
        "# getall_tensor_size()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vgA09HN-DiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "85f96916-b582-4676-c0c1-985ade8b3cfb"
      },
      "source": [
        "plot_loss(recon_arr,\"recon_loss\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"f42792b9-8901-4143-b83e-e3ed9fc66e73\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"f42792b9-8901-4143-b83e-e3ed9fc66e73\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'f42792b9-8901-4143-b83e-e3ed9fc66e73',\n",
              "                        [{\"mode\": \"lines\", \"name\": \"recon_loss\", \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50], \"y\": [967.0229482749834, 967.0105076040978, 966.9894156599964, 966.9534682559722, 966.9203694581518, 966.8858672461612, 966.8705945496029, 966.8474832480704, 966.8241669444482, 966.800595291761, 966.7789008129993, 966.7589725423699, 966.7416436693496, 966.7269408737018, 966.7141901035353, 966.7022669399821, 966.6931554327863, 966.6820694588863, 966.6751510644476, 966.6637693667218, 966.6556122156429, 966.6434003785172, 966.6380654673138, 966.6334630153789, 966.6289822734369, 966.627433756054, 966.6253027561912, 966.6231817556778, 966.6210517801803, 966.6194853928283, 966.6178233153693, 966.6173921551127, 966.615715398843, 966.6134780628163, 966.6112623197276, 966.6102883056748, 966.6096811751037, 966.6089003783085, 966.6086542466558, 966.60830632052, 966.6081342610092, 966.6079165439289, 966.6077844196171, 966.60757979962, 966.6072141071705, 966.6068718874081, 966.6063102526572, 966.6059308084684, 966.6056708252723, 966.6056002306603]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('f42792b9-8901-4143-b83e-e3ed9fc66e73');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQETW799qju9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c08db55-afac-4519-f3d3-ba82dec02cac"
      },
      "source": [
        "model.eval()\n",
        "\n",
        "x_list = []\n",
        "phi_list = []\n",
        "beta_list = []\n",
        "labels_list = []\n",
        "doc_ids = []\n",
        "zx_phi_list=[]\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    for d,batch_ndx in enumerate(all_indices):\n",
        "        # start = time.time()\n",
        "        n_s_v = n_s_v_dict[d].to_dense()\n",
        "        input_w = n_s_v.sum(dim=1).to(device)\n",
        "        gpu_n_s_v = n_s_v.to(device)\n",
        "        labels = train_label[batch_ndx]\n",
        "\n",
        "        kws_b = kws[batch_ndx].to(device)\n",
        "        kI = key_indicator[batch_ndx].to(device)\n",
        "\n",
        "        labels_list.extend(labels)\n",
        "        z, zx, zx_phi = model(input_w, kI,kws_b, gpu_n_s_v, compute_loss=False)\n",
        "\n",
        "        zx = zx.view(-1, num_coordinate).data.detach().cpu().numpy()\n",
        "        zx_phi = zx_phi.view(-1, num_topic).data.detach().cpu().numpy()\n",
        "        zx_phi_list.extend(zx_phi)\n",
        "        x_list.extend(zx)\n",
        "        doc_ids.extend(batch_ndx)\n",
        "\n",
        "    x_list = np.array(x_list)\n",
        "\n",
        "    beta = model.decoder.weight.data.cpu().numpy().T#\n",
        "    zphi = model.decoder_phi_bn(model.centres).data.cpu().numpy()\n",
        "\n",
        "    # query_center = model.query_center.data.cpu().numpy()\n",
        "    print(\"---\"*10)\n",
        "    topword_topics = get_topwords(beta, id_vocab)\n",
        "    topword_topics_list=[]\n",
        "\n",
        "    for topwords in topword_topics:\n",
        "        topword_topics_list.append(topwords.split())\n",
        "        print(topwords)\n",
        "    print(\"---\"*10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "0: government minister wa law blair prime lord response involved official\n",
            "1: politics help britain turned poor minister trusted affair cent thing\n",
            "2: politics wa driven thought impossible british figure purpose day seek\n",
            "3: minister prime stand year help government context comment response thing\n",
            "4: security europe scare longterm user participation campaign popularity equity suffered\n",
            "5: minister prime politics party ambition problem politician written today withdraw\n",
            "6: terror government tyranny protected majority account sullivan case party help\n",
            "7: government ha russian threatened sue city remaining sensible industry majority\n",
            "8: government security build sure position cairn partner creative commitment strategy\n",
            "9: british politics electorate celebrated convention written thing accept government work\n",
            "10: government industry problem aware national social science politics british electorate\n",
            "11: government claim democratic purpose decade tory agency poverty denied anger\n",
            "12: government sullivan case owned company staff arm finger minister experienced\n",
            "13: government risk finance political friday spectrum spend indian estimate talk\n",
            "14: government politics accept work money initiative written thing additional decision\n",
            "15: government insisted reform continue celebrated convention guarantee vote time arm\n",
            "16: security extra pledged service politician national politics turned britain government\n",
            "17: government chief nation spokesman convention pick choose ha consequence action\n",
            "18: government imf help decide dubbed experienced minister routine fantasy function\n",
            "19: ambition written security system thing build wrong politician engage british\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUo3HVV8-Olj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3992432-4ec4-495c-b7ea-4c8fe1adfe37"
      },
      "source": [
        "get_keywords()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['minister', 'security', 'politics', 'government']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4n_hznlqjvD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b709a6b-650b-4f8e-cb76-b82e6d706d51"
      },
      "source": [
        "# Visualization\n",
        "plot_fig(x_list, labels_list, zphi,query_center=0.0,lim = (-50,50) ,contour='No')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x1440 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlzeiAEMMMRJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "906ec063-2d2d-4564-d767-39cf05d57b04"
      },
      "source": [
        "x_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.1580879 , 0.28177962],\n",
              "       [0.19387446, 0.28553244],\n",
              "       [0.19759357, 0.2861639 ],\n",
              "       ...,\n",
              "       [0.1796726 , 0.2795134 ],\n",
              "       [0.17756705, 0.27714792],\n",
              "       [0.19815595, 0.28206152]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3PsQoIic0i_"
      },
      "source": [
        "# # v = (-3.6228485, -4.950025)   # 0.5\n",
        "# v = (9.539641, 6.7072)          # 0.001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFWZmYrdcXIt"
      },
      "source": [
        "# v = torch.tensor(v)\n",
        "# nor = torch.norm(v)\n",
        "# Zscore=torch.exp(-0.5 * (torch.pow(nor,2))/mu_div)\n",
        "# print(Zscore)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPjXwIa8S-yj"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17L02HE1d2EZ"
      },
      "source": [
        "# Stop Here!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7bZi8TUdogt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "outputId": "78bfbe5c-2f8f-4463-be3a-4e21781bdd3e"
      },
      "source": [
        "Stop here!!"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-46-9a36c5f677b6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Stop here!!\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHeUvin1UYy2"
      },
      "source": [
        "# Download pickle from Dropbox (Documents) - No Need to Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKjLnzJiUlFK"
      },
      "source": [
        "!wget https://www.dropbox.com/s/jyiyte9vmkwojee/50_embeddings_load_20news_docs.pkl\n",
        "#!wget https://www.dropbox.com/s/py3j67m5jnzmqlt/50_docs_preprocessed.pkl\n",
        "#!wget https://www.dropbox.com/s/j5vex21bdcfhaqy/50_docs_labels.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acEsPCrNEl-Q"
      },
      "source": [
        "# !wget https://www.dropbox.com/s/9v5ar9xu2dv4e04/data_twentynews_preprocessed.pkl\n",
        "# !wget https://www.dropbox.com/s/09y9y1h0xk3cxaj/embeddings_twentynews.pkl\n",
        "# !wget https://www.dropbox.com/s/ewv3vcwgll0r8a7/data_twentynews_labels.pkl\n",
        "# !wget https://www.dropbox.com/s/chpjn9lzr7rmn2k/fixed_data_twentynews_preprocessed.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFXlj4SBOjT-"
      },
      "source": [
        "# !wget https://www.dropbox.com/s/8khmuj31il8zgkp/data_reuters_labels.pkl\n",
        "# !wget https://www.dropbox.com/s/bgc1ht0jsyjed6s/embeddings_reuters.pkl\n",
        "# !wget https://www.dropbox.com/s/9fk30bjzeefvhgl/data_reuters_preprocessed.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7gmfMHjFD6z"
      },
      "source": [
        "# !wget https://www.dropbox.com/s/52eoulcm5807npk/data_arxiv_preprocessed.pkl\n",
        "# !wget https://www.dropbox.com/s/zgjy9575pcj5v67/embeddings_arxiv.pkl\n",
        "# !wget https://www.dropbox.com/s/xzvshpgvwiy3spz/data_arxiv_labels.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqdDSogFIek3"
      },
      "source": [
        "# !wget https://www.dropbox.com/s/c6wlr148lhwsbaz/embeddings_wos.pkl\n",
        "# !wget https://www.dropbox.com/s/j96061ln6oeejkf/data_wos_preprocessed.pkl\n",
        "# !wget https://www.dropbox.com/s/kiffa4nidkjt7wi/data_wos_labels.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ma1b5gX2XypH"
      },
      "source": [
        "# !wget https://www.dropbox.com/s/wz88fk42r0viqvo/data_webkb_preprocessed.pkl\n",
        "# !wget https://www.dropbox.com/s/8oi5qactwrar1ad/data_webkb_labels.pkl\n",
        "# !wget https://www.dropbox.com/s/go7r4h39q6l01d5/embeddings_webkb.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkoX5Yna0xYk"
      },
      "source": [
        "#Data preprocessing (No need to run)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD-MvQv20wkx",
        "cellView": "form",
        "outputId": "373b691e-6b33-451e-9fa3-c391929c5741"
      },
      "source": [
        "#@title Download Stopwords , punkt, wordnet\n",
        "import nltk\n",
        "# nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "#@title Imports\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torch import nn\n",
        "import re\n",
        "from time import time\n",
        "import numpy as np\n",
        "import collections\n",
        "import torch.optim as optim\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "#@title preprocessing non-stem\n",
        "import sklearn\n",
        "import re\n",
        "import string\n",
        "from numpy import random\n",
        "# from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk import word_tokenize\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# stem = PorterStemmer()\n",
        "wnl = WordNetLemmatizer()\n",
        "stopwords = ['cant','better','well','going','will','would','know','dont','get','like','think','im',\"also\",\"said\",\"a\", \"able\", \"about\", \"above\", \"abst\", \"accordance\", \"according\", \"accordingly\", \"across\", \"act\", \"actually\", \"added\", \"adj\", \"affected\", \"affecting\", \"affects\", \"after\", \"afterwards\", \"again\", \"against\", \"ah\", \"all\", \"almost\", \"alone\", \"along\", \"already\", \"also\", \"although\", \"always\", \"am\", \"among\", \"amongst\", \"an\", \"and\", \"announce\", \"another\", \"any\", \"anybody\", \"anyhow\", \"anymore\", \"anyone\", \"anything\", \"anyway\", \"anyways\", \"anywhere\", \"apparently\", \"approximately\", \"are\", \"aren\", \"arent\", \"arise\", \"around\", \"as\", \"aside\", \"ask\", \"asking\", \"at\", \"auth\", \"available\", \"away\", \"awfully\", \"b\", \"back\", \"be\", \"became\", \"because\", \"become\", \"becomes\", \"becoming\", \"been\", \"before\", \"beforehand\", \"begin\", \"beginning\", \"beginnings\", \"begins\", \"behind\", \"being\", \"believe\", \"below\", \"beside\", \"besides\", \"between\", \"beyond\", \"biol\", \"both\", \"brief\", \"briefly\", \"but\", \"by\", \"c\", \"ca\", \"came\", \"can\", \"cannot\", \"can't\", \"cause\", \"causes\", \"certain\", \"certainly\", \"co\", \"com\", \"come\", \"comes\", \"contain\", \"containing\", \"contains\", \"could\", \"couldnt\", \"d\", \"date\", \"did\", \"didn't\", \"different\", \"do\", \"does\", \"doesn't\", \"doing\", \"done\", \"don't\", \"down\", \"downwards\", \"due\", \"during\", \"e\", \"each\", \"ed\", \"edu\", \"effect\", \"eg\", \"eight\", \"eighty\", \"either\", \"else\", \"elsewhere\", \"end\", \"ending\", \"enough\", \"especially\", \"et\", \"et-al\", \"etc\", \"even\", \"ever\", \"every\", \"everybody\", \"everyone\", \"everything\", \"everywhere\", \"ex\", \"except\", \"f\", \"far\", \"few\", \"ff\", \"fifth\", \"first\", \"five\", \"fix\", \"followed\", \"following\", \"follows\", \"for\", \"former\", \"formerly\", \"forth\", \"found\", \"four\", \"from\", \"further\", \"furthermore\", \"g\", \"gave\", \"get\", \"gets\", \"getting\", \"give\", \"given\", \"gives\", \"giving\", \"go\", \"goes\", \"gone\", \"got\", \"gotten\", \"h\", \"had\", \"happens\", \"hardly\", \"has\", \"hasn't\", \"have\", \"haven't\", \"having\", \"he\", \"hed\", \"hence\", \"her\", \"here\", \"hereafter\", \"hereby\", \"herein\", \"heres\", \"hereupon\", \"hers\", \"herself\", \"hes\", \"hi\", \"hid\", \"him\", \"himself\", \"his\", \"hither\", \"home\", \"how\", \"howbeit\", \"however\", \"hundred\", \"i\", \"id\", \"ie\", \"if\", \"i'll\", \"im\", \"immediate\", \"immediately\", \"importance\", \"important\", \"in\", \"inc\", \"indeed\", \"index\", \"information\", \"instead\", \"into\", \"invention\", \"inward\", \"is\", \"isn't\", \"it\", \"itd\", \"it'll\", \"its\", \"itself\", \"i've\", \"j\", \"just\", \"k\", \"keep  keeps\", \"kept\", \"kg\", \"km\", \"know\", \"known\", \"knows\", \"l\", \"largely\", \"last\", \"lately\", \"later\", \"latter\", \"latterly\", \"least\", \"less\", \"lest\", \"let\", \"lets\", \"like\", \"liked\", \"likely\", \"line\", \"little\", \"'ll\", \"look\", \"looking\", \"looks\", \"ltd\", \"m\", \"made\", \"mainly\", \"make\", \"makes\", \"many\", \"may\", \"maybe\", \"me\", \"mean\", \"means\", \"meantime\", \"meanwhile\", \"merely\", \"mg\", \"might\", \"million\", \"miss\", \"ml\", \"more\", \"moreover\", \"most\", \"mostly\", \"mr\", \"mrs\", \"much\", \"mug\", \"must\", \"my\", \"myself\", \"n\", \"na\", \"name\", \"namely\", \"nay\", \"nd\", \"near\", \"nearly\", \"necessarily\", \"necessary\", \"need\", \"needs\", \"neither\", \"never\", \"nevertheless\", \"new\", \"next\", \"nine\", \"ninety\", \"no\", \"nobody\", \"non\", \"none\", \"nonetheless\", \"noone\", \"nor\", \"normally\", \"nos\", \"not\", \"noted\", \"nothing\", \"now\", \"nowhere\", \"o\", \"obtain\", \"obtained\", \"obviously\", \"of\", \"off\", \"often\", \"oh\", \"ok\", \"okay\", \"old\", \"omitted\", \"on\", \"once\", \"one\", \"ones\", \"only\", \"onto\", \"or\", \"ord\", \"other\", \"others\", \"otherwise\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"outside\", \"over\", \"overall\", \"owing\", \"own\", \"p\", \"page\", \"pages\", \"part\", \"particular\", \"particularly\", \"past\", \"per\", \"perhaps\", \"placed\", \"please\", \"plus\", \"poorly\", \"possible\", \"possibly\", \"potentially\", \"pp\", \"predominantly\", \"present\", \"previously\", \"primarily\", \"probably\", \"promptly\", \"proud\", \"provides\", \"put\", \"q\", \"que\", \"quickly\", \"quite\", \"qv\", \"r\", \"ran\", \"rather\", \"rd\", \"re\", \"readily\", \"really\", \"recent\", \"recently\", \"ref\", \"refs\", \"regarding\", \"regardless\", \"regards\", \"related\", \"relatively\", \"research\", \"respectively\", \"resulted\", \"resulting\", \"results\", \"right\", \"run\", \"s\", \"said\", \"same\", \"saw\", \"say\", \"saying\", \"says\", \"sec\", \"section\", \"see\", \"seeing\", \"seem\", \"seemed\", \"seeming\", \"seems\", \"seen\", \"self\", \"selves\", \"sent\", \"seven\", \"several\", \"shall\", \"she\", \"shed\", \"she'll\", \"shes\", \"should\", \"shouldn't\", \"show\", \"showed\", \"shown\", \"showns\", \"shows\", \"significant\", \"significantly\", \"similar\", \"similarly\", \"since\", \"six\", \"slightly\", \"so\", \"some\", \"somebody\", \"somehow\", \"someone\", \"somethan\", \"something\", \"sometime\", \"sometimes\", \"somewhat\", \"somewhere\", \"soon\", \"sorry\", \"specifically\", \"specified\", \"specify\", \"specifying\", \"still\", \"stop\", \"strongly\", \"sub\", \"substantially\", \"successfully\", \"such\", \"sufficiently\", \"suggest\", \"sup\", \"sure    t\", \"take\", \"taken\", \"taking\", \"tell\", \"tends\", \"th\", \"than\", \"thank\", \"thanks\", \"thanx\", \"that\", \"that'll\", \"thats\", \"that've\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"thence\", \"there\", \"thereafter\", \"thereby\", \"thered\", \"therefore\", \"therein\", \"there'll\", \"thereof\", \"therere\", \"theres\", \"thereto\", \"thereupon\", \"there've\", \"these\", \"they\", \"theyd\", \"they'll\", \"theyre\", \"they've\", \"think\", \"this\", \"those\", \"thou\", \"though\", \"thoughh\", \"thousand\", \"throug\", \"through\", \"throughout\", \"thru\", \"thus\", \"til\", \"tip\", \"to\", \"together\", \"too\", \"took\", \"toward\", \"towards\", \"tried\", \"tries\", \"truly\", \"try\", \"trying\", \"ts\", \"twice\", \"two\", \"u\", \"un\", \"under\", \"unfortunately\", \"unless\", \"unlike\", \"unlikely\", \"until\", \"unto\", \"up\", \"upon\", \"ups\", \"us\", \"use\", \"used\", \"useful\", \"usefully\", \"usefulness\", \"uses\", \"using\", \"usually\", \"v\", \"value\", \"various\", \"'ve\", \"very\", \"via\", \"viz\", \"vol\", \"vols\", \"vs\", \"w\", \"want\", \"wants\", \"was\", \"wasnt\", \"way\", \"we\", \"wed\", \"welcome\", \"we'll\", \"went\", \"were\", \"werent\", \"we've\", \"what\", \"whatever\", \"what'll\", \"whats\", \"when\", \"whence\", \"whenever\", \"where\", \"whereafter\", \"whereas\", \"whereby\", \"wherein\", \"wheres\", \"whereupon\", \"wherever\", \"whether\", \"which\", \"while\", \"whim\", \"whither\", \"who\", \"whod\", \"whoever\", \"whole\", \"who'll\", \"whom\", \"whomever\", \"whos\", \"whose\", \"why\", \"widely\", \"willing\", \"wish\", \"with\", \"within\", \"without\", \"wont\", \"words\", \"world\", \"would\", \"wouldnt\", \"www\", \"x\", \"y\", \"yes\", \"yet\", \"you\", \"youd\", \"you'll\", \"your\", \"youre\", \"yours\", \"yourself\", \"yourselves\", \"you've\", \"z\", \"zero\"]\n",
        "\n",
        "def preprocessing_nonstem(doc,word2vec_model,my_punctuation):\n",
        "    # print(doc)\n",
        "    # word_vectors = word2vec_model.wv\n",
        "    doc = doc.lower()\n",
        "    # print(doc)\n",
        "    doc = doc.translate(str.maketrans('', '', my_punctuation))\n",
        "    doc = word_tokenize(doc)\n",
        "    doc = filter(lambda x: x not in my_punctuation, doc)\n",
        "    # doc = filter(lambda x:x not in stopwords, doc)\n",
        "    doc = filter(lambda x:not x.isdigit(), doc)\n",
        "    doc = [wnl.lemmatize(w.lower()) for w in doc]\n",
        "    # doc = filter(lambda x: x in word2vec_model.vocab,doc)\n",
        "    doc = filter(lambda x:x not in stopwords, doc)\n",
        "    doc = filter(lambda x: x in word2vec_model.vocab or x in \".\",doc)\n",
        "    # doc = filter(lambda x:x not in stopwords, doc)\n",
        "    doc = ' '.join(e for e in doc)\n",
        "    return doc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJZtEpPf1Ubk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b69ef6c-898e-4c82-f117-4720d19a7757"
      },
      "source": [
        "!wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n",
        "!gunzip GoogleNews-vectors-negative300.bin.gz\n",
        "from gensim import models\n",
        "word2vec_model = models.KeyedVectors.load_word2vec_format('./GoogleNews-vectors-negative300.bin', binary=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-02 00:40:59--  https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 52.216.25.46\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|52.216.25.46|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1647046227 (1.5G) [application/x-gzip]\n",
            "Saving to: ‘GoogleNews-vectors-negative300.bin.gz’\n",
            "\n",
            "GoogleNews-vectors- 100%[===================>]   1.53G  16.6MB/s    in 97s     \n",
            "\n",
            "2021-02-02 00:42:37 (16.3 MB/s) - ‘GoogleNews-vectors-negative300.bin.gz’ saved [1647046227/1647046227]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "usMtzpC06t1s"
      },
      "source": [
        "#@title function : load / save pickle_obj\n",
        "import pickle\n",
        "\n",
        "def save_obj(obj, name):\n",
        "    with open(name + '.pkl', 'wb') as f:\n",
        "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "def load_obj(name):\n",
        "    with open(name + '.pkl', 'rb') as f:\n",
        "        return pickle.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dVnRxJaCslhe"
      },
      "source": [
        "def get_bbc_data():\n",
        "\n",
        "  import os\n",
        "  import glob\n",
        "  os.system('wget https://www.dropbox.com/s/vunli21d312x55g/bbc.zip')\n",
        "  os.system('wget https://www.dropbox.com/s/h6y9zfdb76gl4uz/bbc-fulltext.zip')\n",
        "  os.system('unzip bbc.zip')\n",
        "  os.system('unzip bbc-fulltext.zip')\n",
        "\n",
        "  # BBC Docs -\n",
        "  corpus = []\n",
        "  subfolders = [f.path for f in os.scandir(os.getcwd()+'/bbc') if f.is_dir()]\n",
        "  subfolders = sorted(subfolders)\n",
        "  for s in subfolders:\n",
        "    files_list = sorted(glob.glob(s+\"/*.txt\"))\n",
        "    for file in files_list:\n",
        "      with open(file, \"rb\") as f:\n",
        "        content = f.readlines()\n",
        "        content = [x.strip().lower().decode('ISO-8859-1') for x in content]\n",
        "        corpus.append(''.join(content))\n",
        "\n",
        "  # BBC_labels -\n",
        "  with open(\"bbc.classes\", \"r\") as f:\n",
        "    content = f.readlines()\n",
        "    content = [x.strip()[::-1][0] for x in content]\n",
        "    labels = content[4:]\n",
        "    label_dict = {'0':'business','1':'entertainment','2':'politics','3':'sport','4':'tech'}\n",
        "  for l in range(len(labels)):\n",
        "    labels[l] = label_dict[labels[l]]\n",
        "\n",
        "  return corpus,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZxidHJvujq2D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f60eb1-3e70-40ad-f8fa-c09865da4502"
      },
      "source": [
        "docs,labels = get_bbc_data()\n",
        "len(docs),len(labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2225, 2225)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPzklfKYm8da",
        "outputId": "9276702f-0631-40c4-de12-9c2c08c0a68d"
      },
      "source": [
        "list(zip(*np.unique(labels, return_counts=True)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('business', 510),\n",
              " ('entertainment', 386),\n",
              " ('politics', 417),\n",
              " ('sport', 511),\n",
              " ('tech', 401)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH2pSst53XyM"
      },
      "source": [
        "dots = [(\". \"*k).strip() for k in range(1,100)]\n",
        "def docs_labels_preprocessing(docs,labels,word2vec_model,my_punctuation):\n",
        "  data_preprocessed = []\n",
        "  data_preprocessed_labels = []\n",
        "  for i in range(len(docs)):\n",
        "    doc = preprocessing_nonstem(docs[i],word2vec_model,my_punctuation)\n",
        "    # doc[i] = docs[i].replace(\".\",\"\")\n",
        "    if(doc!='' and (doc not in dots)):\n",
        "      data_preprocessed.append(doc)\n",
        "      data_preprocessed_labels.append(labels[i])\n",
        "  return data_preprocessed,data_preprocessed_labels\n",
        "\n",
        "def docs_sentences_labels_preprocessing(docs,labels,word2vec_model):\n",
        "  doc_preprocessed = []\n",
        "  doc_preprocessed_labels = []\n",
        "  sen_preprocessed = []\n",
        "  doc_id_sent = []\n",
        "  for i in range(len(docs)):\n",
        "    if(i%1000==0): print(i)\n",
        "    doc = ''\n",
        "    sen_list = nltk.tokenize.sent_tokenize(docs[i])\n",
        "    for j in sen_list:\n",
        "      sen = preprocessing_nonstem(j,word2vec_model,string.punctuation)\n",
        "      if(sen!='' and (sen not in dots)):\n",
        "        sen_preprocessed.append(sen)\n",
        "        doc_id_sent.append(len(doc_preprocessed))\n",
        "        doc = doc + ' ' + sen\n",
        "    if(doc!='' and (doc not in dots)):\n",
        "      doc_preprocessed.append(doc)\n",
        "      doc_preprocessed_labels.append(labels[i])\n",
        "  return doc_preprocessed,doc_preprocessed_labels,sen_preprocessed,doc_id_sent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KvUOqln1wk1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0995aa7-69ff-4e25-984d-a17be535c021"
      },
      "source": [
        "doc_preprocessed,doc_preprocessed_labels,sen_preprocessed,doc_id_sent=docs_sentences_labels_preprocessing(docs,labels,word2vec_model)\n",
        "# save_obj(doc_preprocessed,'doc_preprocessed')\n",
        "# save_obj(doc_preprocessed_labels, 'doc_preprocessed_labels')\n",
        "# save_obj(sen_preprocessed,'sen_preprocessed')\n",
        "# save_obj(doc_id_sent,'doc_id_sent')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XthlCZTzRnuZ"
      },
      "source": [
        "def create_doc_sentences(doc_id_sent):\n",
        "  doc_sentences = []\n",
        "  num_doc = max(doc_id_sent)+1\n",
        "  for i in range(num_doc):\n",
        "    if(i%1000==0):\n",
        "      print(i)\n",
        "    indices = [j for j, x in enumerate(doc_id_sent) if x == i]\n",
        "    doc_sentences.append(indices)\n",
        "  return doc_sentences\n",
        "\n",
        "def preprocessed_data(sens, docs, labels, word2vec_model):\n",
        "  vectorizer = CountVectorizer(max_features=5000,dtype=np.float32)\n",
        "  train_vec = vectorizer.fit_transform(sens).toarray()\n",
        "  vocab = vectorizer.vocabulary_\n",
        "  nonzeros_indexes = np.where(train_vec.any(1))[0]\n",
        "  train_vec_non_zeros = [train_vec[i] for i in nonzeros_indexes]\n",
        "  sens_non_zeros = [sens[i] for i in nonzeros_indexes]\n",
        "  doc_sent_id_non_zeroes = [doc_id_sent[i] for i in nonzeros_indexes]\n",
        "  train_label =[]\n",
        "  keep_docs = []\n",
        "  doc_preprocessed_nonzeroes = []\n",
        "  for i in doc_sent_id_non_zeroes:\n",
        "    if(i not in keep_docs):\n",
        "      keep_docs.append(i)\n",
        "  for i,j in enumerate(keep_docs):\n",
        "    if(i%1000==0): print(i)\n",
        "    doc_preprocessed_nonzeroes.append(doc_preprocessed[j])\n",
        "    train_label.append(labels[j])\n",
        "\n",
        "    for k,l in enumerate(doc_sent_id_non_zeroes):\n",
        "      if(l==j): doc_sent_id_non_zeroes[k]=i\n",
        "\n",
        "  embeddings = {}\n",
        "  for f in vocab:\n",
        "    embeddings[f] = word2vec_model[f]\n",
        "\n",
        "  save_obj(embeddings,'embeddings')\n",
        "  save_obj(doc_sent_id_non_zeroes, 'doc_id_sent_nonzeros')\n",
        "  save_obj(doc_preprocessed_nonzeroes,'doc_preprocessed_nonzeroes')\n",
        "  save_obj(train_label,'doc_preprocessed_nonzeroes_labels')\n",
        "  save_obj(sens_non_zeros, 'sen_preprocessed_nonzeroes')\n",
        "  save_obj(train_vec, 'train_vec')\n",
        "  save_obj(train_vec_non_zeros, 'train_vec_non_zeros')\n",
        "  save_obj(vocab, 'vocab')\n",
        "  return sens_non_zeros, train_label, train_vec_non_zeros, vocab, doc_sent_id_non_zeroes, embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vecLyx7RsOl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2e21b69-6239-429d-a85b-1d9e5446dbea"
      },
      "source": [
        "import gc\n",
        "sens_non_zeros, train_label, train_vec_non_zeros, vocab, doc_sent_id_non_zeroes, embeddings = preprocessed_data(sen_preprocessed,doc_preprocessed,doc_preprocessed_labels,word2vec_model)\n",
        "doc_sentences = create_doc_sentences(doc_sent_id_non_zeroes)\n",
        "save_obj(doc_sentences,'doc_sentences')\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "1000\n",
            "2000\n",
            "0\n",
            "1000\n",
            "2000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0_bcLEl7OGe",
        "outputId": "caa6a140-9227-4f9f-c82b-6be85f9be8d7"
      },
      "source": [
        "len(doc_sent_id_non_zeroes), doc_sentences[-1][-1]+1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(33571, 33571)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jvkxejFy4oe",
        "outputId": "28837eb8-e5b3-4eab-adc4-b8a4ad7805db"
      },
      "source": [
        "!zip data_bbc.zip *.pkl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: doc_id_sent_nonzeros.pkl (deflated 95%)\n",
            "  adding: doc_preprocessed_nonzeroes_labels.pkl (deflated 97%)\n",
            "  adding: doc_preprocessed_nonzeroes.pkl (deflated 66%)\n",
            "  adding: doc_sentences.pkl (deflated 31%)\n",
            "  adding: embeddings.pkl (deflated 54%)\n",
            "  adding: sen_preprocessed_nonzeroes.pkl (deflated 64%)\n",
            "  adding: train_vec_non_zeros.pkl (deflated 100%)\n",
            "  adding: train_vec.pkl (deflated 100%)\n",
            "  adding: vocab.pkl (deflated 71%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUN-kXACfgBK"
      },
      "source": [
        "# !zip train_vec.zip train_vec.pkl\n",
        "# !zip train_vec_non_zeros.zip train_vec_non_zeros.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "CBRe8eK20R7t",
        "outputId": "f7c48114-5138-45ba-c9ca-9ea503d81a3c"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"data_bbc.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4a6f8496-5791-4644-8d2d-c5bf4375dd8c\", \"data_bbc.zip\", 8123103)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "hC7YhIYiAWkb",
        "outputId": "de0458a7-696a-4bdf-faad-c21199dfc2f7"
      },
      "source": [
        "Score Not Used Anymore"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-08d19fc4e2dd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    Score Not Used Anymore\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQAYr-SEYEsN"
      },
      "source": [
        "def cosine_similarity_desm_docs(query_list, train_vec, vocab, embeddings):\n",
        "  num_docs = len(train_vec)\n",
        "  num_voc = len(vocab)\n",
        "  sim_list = torch.zeros(num_docs)\n",
        "  index = 0\n",
        "  id_vocab = dict(map(reversed, vocab.items()))\n",
        "  for d in range(num_docs):\n",
        "    if(d%5000==0): print(d)\n",
        "    doc_bar = torch.zeros(300)\n",
        "    doc_length = 0\n",
        "    for v in range(num_voc):\n",
        "      if(train_vec[d][v]>0):\n",
        "        doc_bar.add_(train_vec[d][v] * torch.from_numpy(embeddings[id_vocab[v]])/torch.norm(torch.from_numpy(embeddings[id_vocab[v]])))\n",
        "        doc_length = doc_length + train_vec[d][v]\n",
        "    doc_bar = doc_bar / doc_length\n",
        "    sum = 0\n",
        "\n",
        "    for q in query_list:\n",
        "      sum += torch.dot(torch.from_numpy(embeddings[q]) , doc_bar)/(torch.norm(torch.from_numpy(embeddings[q]))*torch.norm(doc_bar))\n",
        "    sum = sum/len(query_list)\n",
        "    sim_list[index]=sum\n",
        "    index = index + 1\n",
        "\n",
        "  return sim_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxdjcTr9X_J6"
      },
      "source": [
        "keywords = get_keywords()\n",
        "all_rscores = cosine_similarity_desm_docs(keywords, train_vec_non_zeros, vocab, embeddings)\n",
        "save_obj(all_rscores, 'all_rscores')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MvJelmXZUlHy"
      },
      "source": [
        "# Download pickle from Dropbox (50 Sentences)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-2Cs4pTOTvx_"
      },
      "source": [
        "# !wget https://www.dropbox.com/s/408eefyszxnadke/50_data_load_20news_sentences_labels.pkl\n",
        "# !wget https://www.dropbox.com/s/hqq00bqababxovo/50_data_load_20news_sentences_preprocessed.pkl\n",
        "# !wget https://www.dropbox.com/s/e63a0ew3y7ktz17/50_doc_id_sent_load_20news_sentences.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jCrmPj6uhZM4"
      },
      "source": [
        "#Testing - No Need to Run"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "2aoUqeoo20hq"
      },
      "source": [
        "#@title All variables occupying memory\n",
        "import sys\n",
        "local_vars = list(locals().items())\n",
        "sum = 0\n",
        "for var, obj in local_vars:\n",
        "    #sum = sum + sys.getsizeof(obj)/1e9\n",
        "    print(var, sys.getsizeof(obj)/1e9)\n",
        "print(sum)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "ep4R4oR64ztV"
      },
      "source": [
        "#@title Variables occupying large amt of mem\n",
        "import sys\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['','Ki','Mi','Gi','Ti','Pi','Ei','Zi']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return \"%3.1f %s%s\" % (num, unit, suffix)\n",
        "        num /= 1024.0\n",
        "    return \"%.1f %s%s\" % (num, 'Yi', suffix)\n",
        "\n",
        "for name, size in sorted(((name, sys.getsizeof(value)) for name, value in locals().items()),\n",
        "                         key= lambda x: -x[1])[:10]:\n",
        "    print(\"{:>30}: {:>8}\".format(name, sizeof_fmt(size)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYuPQevRdsEa"
      },
      "source": [
        "#Normalized all_rscores(DESM) (Not Used)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkvzqQMNXbuK"
      },
      "source": [
        "# torch.max(all_rscores)\n",
        "# keywords = get_keywords()\n",
        "# top_10_docs=[]\n",
        "# sort,indices = torch.sort(all_rscores,descending=True)\n",
        "# print('Keywords',get_keywords())\n",
        "# print('Descending :',sort,'\\n','indices:',indices)\n",
        "# print('\\n\\n Top 10 Relevant Documents (DESM):\\n\\n',\"---\"*40)\n",
        "\n",
        "# for k in range(10):\n",
        "#     print(k+1,') ',sen_preprocessed[indices[k].item()])\n",
        "#     print(k+1,')',doc_preprocessed_labels[doc_id_sent[indices[k].item()]])\n",
        "# with open(\"1000.txt\", \"w\") as output:\n",
        "#   for k in range(0,1000):\n",
        "#     output.write(str(k+1)+')  '+sen_preprocessed[indices[k].item()]+'\\n')\n",
        "#     output.write(str(k+1)+')  '+str(sort[indices[k].item()].item())+'\\n')\n",
        "#     output.write(str(k+1)+')  '+doc_preprocessed_labels[doc_id_sent[indices[k].item()]]+'\\n\\n')\n",
        "\n",
        "#     # print(k+1,') ',preprossed_data_non_zeros[indices[k].item()])\n",
        "#     # print(k+1,')',train_label[indices[k].item()])\n",
        "#     # print()\n",
        "\n",
        "# output.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bELCcZ0Wu-v"
      },
      "source": [
        "# from sklearn.preprocessing import MinMaxScaler\n",
        "# from matplotlib import pyplot as plt\n",
        "# scaler = MinMaxScaler(feature_range=(0+1e-10, 0.99))\n",
        "# normalized_all_rscores = scaler.fit_transform(all_rscores.data.reshape(-1,1))\n",
        "# normalized_all_rscores=torch.tensor(normalized_all_rscores.flatten())\n",
        "# rounded_normalized_all_rscores = torch.round(normalized_all_rscores*10)/10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjB3n6TXrETw"
      },
      "source": [
        "# plt.hist(all_rscores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjLDgIyOMHuq"
      },
      "source": [
        "# plt.hist(rounded_normalized_all_rscores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XN0XvEt6Kc7"
      },
      "source": [
        "# r_origin = rounded_normalized_all_rscores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0eQb3Xv6tau"
      },
      "source": [
        "# r_origin.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTpQ4Mw5X-tV"
      },
      "source": [
        "# for i in range(len(rounded_normalized_all_rscores)):\n",
        "#     for k in keywords:\n",
        "#       if (k in sen_preprocessed[i]):\n",
        "#         rounded_normalized_all_rscores[i] = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbtsqmIwu_bb"
      },
      "source": [
        "# for i in range(len(normalized_all_rscores)):\n",
        "#     for k in keywords:\n",
        "#       if (k in sen_preprocessed[i]):\n",
        "#         normalized_all_rscores[i] = 1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5oZBwHLMFH4"
      },
      "source": [
        "# plt.hist(rounded_normalized_all_rscores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YlpOWN_F1V5l"
      },
      "source": [
        "#Create Relvance Vector(Bernoulli_v1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNXzZpCPg629"
      },
      "source": [
        "# def padarray(A, size,criteria):\n",
        "#     A = list(A)\n",
        "#     if criteria=='top':\n",
        "#       A[::-1].sort()\n",
        "#     elif criteria=='first':\n",
        "#       pass\n",
        "#     t = size - len(A)\n",
        "#     if t<=0:\n",
        "#       return A[:size]\n",
        "#     else:\n",
        "#       # return np.pad(A, irrelv_vector, mode='constant')\n",
        "#       for _ in range(t):\n",
        "#         A.append([0 for _ in range(num_topic)])\n",
        "#       return A"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbC81og5nmHw"
      },
      "source": [
        "# irrelv_vector = [0 for _ in range(num_topic)]\n",
        "# relv_vector = [1 for _ in range(num_topic)]\n",
        "\n",
        "# # Bernoulli f(k;p) = p(k) + (1-p)(1-k) for k={0,1}\n",
        "# # for both k = 0 or k = 1 : if p = 0.5 --> f(k;p) = 0.5\n",
        "# irrelv_vector[0] = 0.5\n",
        "# relv_vector[0] = 0.5\n",
        "\n",
        "# # Without bernoulli\n",
        "# # irrelv_vector[0] = 1\n",
        "# # relv_vector[0] = 0\n",
        "\n",
        "# relv_score_vector = []\n",
        "# keys  = get_keywords()\n",
        "\n",
        "# for s in sen_preprocessed:\n",
        "#   key_indicator = 0\n",
        "#   for k in keys:\n",
        "#     # if k in s:\n",
        "#     if re.search(r'\\b' + k + r'\\b', s):\n",
        "#       key_indicator = 1\n",
        "#       relv_score_vector.append(relv_vector)\n",
        "#       break\n",
        "#   if key_indicator == 0:\n",
        "#     relv_score_vector.append(irrelv_vector)\n",
        "\n",
        "# relv_score_vector =np.array(relv_score_vector)\n",
        "# score = [relv_score_vector[i] for i in doc_sentences]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIsStENqfyQz"
      },
      "source": [
        "# # rounded_list = rounded_normalized_all_rscores.numpy()\n",
        "# for i in range(len(score)):\n",
        "#   score[i] = padarray(score[i],50,'first')\n",
        "# score_all_doc_s_n = torch.tensor(np.array(score))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BpxBWp-waU-"
      },
      "source": [
        "# status_all_doc_s_n = torch.zeros(score_all_doc_s_n.size())\n",
        "# for score in range(score_all_doc_s_n.shape[0]):\n",
        "#   for st in range(score_all_doc_s_n.shape[1]):\n",
        "#     if score_all_doc_s_n[score][st]>torch.tensor(0.0):\n",
        "#       status_all_doc_s_n[score][st] = torch.tensor(1.0,dtype=torch.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD5DxBd71eqd"
      },
      "source": [
        "# Dists, Sigmoid, Old Model (No need to Run)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8MNqCWVYJcl"
      },
      "source": [
        "Other Distributions\n",
        "(Beta, Gaussian, Raised Cosine) etc.."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "uY2AM29sYFOE"
      },
      "source": [
        "# @title\n",
        "# def beta(x,mu,a):\n",
        "#   smoothen=1e-20\n",
        "#   b = (a - a * (mu+smoothen))/(mu+smoothen)\n",
        "#   # a = (b * (mu+smoothen))/((1-mu)+smoothen)\n",
        "#   deno = (torch.lgamma(a)+torch.lgamma(b)-torch.lgamma(a+b))\n",
        "#   ret = (a-1)*torch.log(x) + (b-1)*torch.log(1-x)-deno\n",
        "#   return ret\n",
        "\n",
        "# def log_gaussian(x,mu,variance):\n",
        "#   pi = 3.1415927410125732\n",
        "#   ret = -0.5 * ((x-mu)/variance)**2 - torch.log(variance*(2*pi)**0.5)\n",
        "#   return ret\n",
        "\n",
        "# def raised_cosine(x,mu,s):\n",
        "#   #torch.pi = torch.acos(torch.zeros(1)).item() * 2\n",
        "#   pi = 3.1415927410125732\n",
        "\n",
        "#   check_range = (x > mu-s) & (x < mu+s)\n",
        "#   a = 1.0 / 2*s\n",
        "#   c = (x - mu) / s\n",
        "#   b = torch.cos(pi * c)\n",
        "#   raised_cosine = a*(1+b)\n",
        "\n",
        "#   raised_cosine = raised_cosine * check_range\n",
        "\n",
        "#   return raised_cosine\n",
        "\n",
        "# def LogL_Score_beta(theta,phi,torch_sim):\n",
        "#   # s_rc=1\n",
        "#   # phi_z = torch.norm(phi,dim=-1).unsqueeze(-1) #num_topic --> 50\n",
        "#   # R_phi = torch.exp(-0.5 * (torch.pow(phi_z,2))) # ---> 50 x 1\n",
        "#   # mu = torch.matmul(theta,R_phi) # bs x num_topic * num_topicx1\n",
        "#   # LogL = torch.log(raised_cosine(torch_sim, mu, s_rc)+1e-20)\n",
        "#   #b=torch.tensor(100.0)\n",
        "#   # a=torch.tensor(100.0)\n",
        "\n",
        "#   phi_z = torch.norm(phi,dim=-1).unsqueeze(-1) #num_topic --> 50\n",
        "#   R_phi = torch.exp(-0.5 * (torch.pow(phi_z,2))/100.0 ) # ---> 50 x 1\n",
        "#   mu = torch.matmul(theta,R_phi) # bs x num_topic * num_topicx1\n",
        "#   LogL = beta(torch_sim, mu, a)\n",
        "#   return LogL.sum()\n",
        "\n",
        "# def LogL_Score(x,torch_sim):\n",
        "#   x=x.squeeze(-2)\n",
        "#   variance=torch.tensor(0.1)\n",
        "#   x_norm = torch.norm(x,dim=-1)\n",
        "#   mu = torch.exp(-0.5 * (torch.pow(x_norm,2)))\n",
        "#   LogL = log_gaussian(torch_sim, mu, variance)\n",
        "#   #LogL = beta(torch_sim, mu, b)\n",
        "#   return LogL.sum()\n",
        "\n",
        "# # def LogL_Score_test(zx,relevant_scores):\n",
        "# #   x_norm = torch.norm(zx,dim=-1)\n",
        "# #   NegativeLogL_RScore = 10000 * torch.exp(-0.5 * (torch.pow(x_norm,2)/100.0) - relevant_scores)**2\n",
        "# #   return NegativeLogL_RScore.sum()\n",
        "\n",
        "\n",
        "# def LogL_Score_current(theta,phi,relevant_scores):\n",
        "#   a=torch.tensor(100.0)\n",
        "#   phi_z = torch.norm(phi,dim=-1).unsqueeze(-1)\n",
        "#   R_phi = torch.exp(-0.5 * (torch.pow(phi_z,2)))\n",
        "\n",
        "#   R_n = torch.pow(theta,R_phi)\n",
        "\n",
        "#   LogL = beta(torch_sim, mu, a)\n",
        "#   return LogL.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zVuSR4dGv1Wk"
      },
      "source": [
        "#@title Reverse Sigmoid Function\n",
        "import matplotlib.pylab as plt\n",
        "import numpy as np\n",
        "var = -0.5 # change this to -1.0, -1.5 , -2.0\n",
        "x = np.arange(-8, 8, 0.1)\n",
        "y = np.exp(var*x) / (1 + np.exp(var*x))\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "sggv9MESvwqs"
      },
      "source": [
        "#@title Truncated Normal , Beta ..\n",
        "# def inv_S(r,a,c,D,smoothen):\n",
        "#   numr = 1-c\n",
        "#   deno = 1+ torch.exp(a * ( (2*r)/D - 1))\n",
        "#   invS = numr / (deno + smoothen) + c\n",
        "#   return invS\n",
        "\n",
        "# def beta(x,mu,a):\n",
        "#   smoothen=1e-20\n",
        "#   b = (a - a * (mu+smoothen))/(mu+smoothen)\n",
        "#   # a = (b * (mu+smoothen))/((1-mu)+smoothen)\n",
        "#   deno = (torch.lgamma(a)+torch.lgamma(b)-torch.lgamma(a+b))\n",
        "#   ret = (a-1)*torch.log(x) + (b-1)*torch.log(1-x)-deno\n",
        "#   return ret\n",
        "\n",
        "# def truncate_phi(Xi):\n",
        "#   pi = 3.1415927410125732\n",
        "#   return (1.0/ ((2.0*pi)**0.5) )*torch.exp(-0.5*(Xi**2))\n",
        "\n",
        "# def truncate_bold_phi(x):\n",
        "#   return 0.5 * (1.0 + torch.erf(x / (2.0**0.5)))\n",
        "\n",
        "# def truncate_norm_dist(x,mu,a,b,sig,smoothen):\n",
        "#     check_range = (x >= mu-a) & (x <= mu+b)\n",
        "#     # check_range = (x >= a) & (x<=b)\n",
        "#     l=(1.0/sig)\n",
        "#     r_numr= truncate_phi((x-mu)/sig)\n",
        "#     r_deno= truncate_bold_phi((b-mu)/sig) - truncate_bold_phi((a-mu)/sig)\n",
        "#     tr_ndist = l*(r_numr/(r_deno+smoothen))\n",
        "#     #print(tr_ndist)\n",
        "#     tr_ndist = tr_ndist*check_range\n",
        "#     #print(tr_ndist)\n",
        "#     return tr_ndist\n",
        "\n",
        "\n",
        "# def LogL_Score_TND(theta,phi,relevant_scores, query_center,x):\n",
        "#   smoothen=1e-20\n",
        "#   a=1\n",
        "#   b=1\n",
        "#   sig=0.01\n",
        "\n",
        "#    #phi_z = torch.norm(phi,dim=-1).unsqueeze(-1)\n",
        "\n",
        "#   # phi_z = (phi-query_center.T).pow(2).sum(-1).unsqueeze(-1)\n",
        "#   # R_phi = torch.exp(-0.5 * (torch.pow(phi_z,2))/mu_div)\n",
        "#   # mu = torch.prod(R_phi ** theta.T,0)\n",
        "\n",
        "#   x_norm = (x-query_center.T).pow(2).sum(-1)\n",
        "#   mu = torch.exp(-0.5 * (x_norm)/mu_div)\n",
        "\n",
        "#   # x_norm = torch.norm(x,dim=-1)\n",
        "#   # mu = torch.exp(-0.5 * (torch.pow(x_norm,2))/mu_div)\n",
        "\n",
        "#   # mu = 1.0/(1.0 + (torch.pow(x_norm,2)/mu_div))\n",
        "#   LogL = torch.log(truncate_norm_dist(relevant_scores, mu, a,b,sig,smoothen)+smoothen)\n",
        "\n",
        "\n",
        "  # a = torch.tensor(3.0)\n",
        "  # c = torch.tensor(0.0035)\n",
        "  # D = torch.tensor(23.0)\n",
        "\n",
        "  # # LogL = torch.log(inv_S(x_norm,a,c,D,smoothen)+smoothen)\n",
        "  # return LogL.sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "pRxibQtf3gqi"
      },
      "source": [
        "# @title OLD model\n",
        "# import sklearn\n",
        "# import pickle\n",
        "# import torch\n",
        "# import sys\n",
        "# from torch.utils.data import Dataset, DataLoader\n",
        "# import torch.nn as nn\n",
        "# from sympy.stats import RaisedCosine,density\n",
        "# import torch.nn.functional as F\n",
        "# import torch.optim as optim\n",
        "# import numpy as np\n",
        "# import torch.utils.data as data_utils\n",
        "# from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "# from types import SimpleNamespace\n",
        "# from torch.nn import Parameter\n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "# mu_div = 1500.0\n",
        "# gaussian_variance=torch.tensor(0.05)\n",
        "\n",
        "# def log_gaussian(x,mu,variance):\n",
        "#    pi = 3.1415927410125732\n",
        "#    ret = -0.5 * ((x-mu)/variance)**2 - torch.log(variance*(2*pi)**0.5)\n",
        "#    return ret\n",
        "\n",
        "# def LogL_gaussianScore(x,relevant_scores,query_center):\n",
        "\n",
        "#   # x_norm = torch.norm(x,dim=-1)\n",
        "#   # mu = torch.exp(-0.5 * (torch.pow(x_norm,2))/mu_div )\n",
        "\n",
        "#   x_norm = (x-query_center.T).pow(2).sum(-1)\n",
        "#   mu = torch.exp(-0.5 * (x_norm)/mu_div)\n",
        "\n",
        "#   LogL = log_gaussian(relevant_scores, mu, gaussian_variance)\n",
        "#   return LogL.sum()\n",
        "# ############################################################################################\n",
        "\n",
        "\n",
        "# def gaussian(alpha):\n",
        "#     # phi = torch.exp(-5*alpha)\n",
        "#     phi = -0.5*alpha\n",
        "#     return phi\n",
        "\n",
        "# def inverse_multi_quadric(alpha):\n",
        "#     phi = -0.5*torch.log(torch.ones_like(alpha) + alpha)\n",
        "#     return phi\n",
        "\n",
        "# def inverse_quadratic(alpha):\n",
        "#     # phi = torch.ones_like(alpha) / (torch.ones_like(alpha) + alpha)\n",
        "#     phi = -torch.log(torch.ones_like(alpha) + alpha)\n",
        "#     return phi\n",
        "\n",
        "# class PlsvVAE(nn.Module):\n",
        "#     def __init__(self, num_input, en1_units_x, en2_units_x, num_coordinate, num_topic, drop_rate, variance_x, bs, distance=\"gaussian\"):\n",
        "#         super(PlsvVAE, self).__init__()\n",
        "#         self.num_input, self.num_coordinate, self.num_topic, self.variance_x, self.bs\\\n",
        "#             = num_input, num_coordinate, num_topic, variance_x, bs\n",
        "\n",
        "#         # encoder\n",
        "#         self.en1_fc     = nn.Linear(num_input, en1_units_x)             # V -> 100 #nxV->(vxh1)->nxh1;\n",
        "#         self.en2_fc     = nn.Linear(en1_units_x, en2_units_x)             # 100  -> 100\n",
        "#         self.en2_drop   = nn.Dropout(drop_rate)\n",
        "#         self.mean_fc    = nn.Linear(en2_units_x, num_coordinate)        # 100  -> 2\n",
        "#         self.mean_bn    = nn.BatchNorm1d(num_coordinate)              # bn for mean\n",
        "#         self.logvar_fc  = nn.Linear(en2_units_x, num_coordinate)        # 100  -> 2\n",
        "#         self.logvar_bn  = nn.BatchNorm1d(num_coordinate)              # bn for logvar\n",
        "\n",
        "\n",
        "#         # RBF\n",
        "#         self.in_features = self.num_coordinate\n",
        "#         self.out_features = self.num_topic\n",
        "#         self.centres = nn.Parameter(torch.Tensor(self.out_features, self.in_features))\n",
        "\n",
        "\n",
        "#         self.query_center = nn.Parameter(torch.zeros(2,1))\n",
        "\n",
        "#         if distance==\"gaussian\":\n",
        "#             self.basis_func = gaussian\n",
        "#         if distance==\"inverse_quadratic\":\n",
        "#             self.basis_func = inverse_quadratic\n",
        "#         if distance==\"inverse_multi_quadric\":\n",
        "#             self.basis_func = inverse_multi_quadric\n",
        "#         self.init_parameters()\n",
        "\n",
        "\n",
        "#         # decoder layer\n",
        "#         self.decoder    = nn.Linear(self.num_topic, self.num_input)             # 50   -> 1995\n",
        "#         self.decoder_bn = nn.BatchNorm1d(self.num_topic)                      # bn for decoder\n",
        "\n",
        "#         # decoder document\n",
        "#         self.decoder_phi_bn = nn.BatchNorm1d(num_coordinate)                      # bn for decoder\n",
        "#         self.decoder_x_bn = nn.BatchNorm1d(num_coordinate)\n",
        "\n",
        "#         # prior mean and variance as constant buffers\n",
        "#         prior_mean   = torch.Tensor(1, num_coordinate).fill_(0)\n",
        "#         prior_var    = torch.Tensor(1, num_coordinate).fill_(variance_x)\n",
        "#         self.prior_mean = nn.Parameter(prior_mean, requires_grad=False)\n",
        "#         self.prior_var  = nn.Parameter(prior_var, requires_grad=False)\n",
        "#         self.prior_logvar = nn.Parameter(prior_var.log(), requires_grad=False)\n",
        "\n",
        "\n",
        "#     def init_parameters(self):\n",
        "#         nn.init.normal_(self.centres, 0, 0.01)\n",
        "\n",
        "#     def encode(self, input_):\n",
        "#         N, *_ = input_.size()\n",
        "#         # compute posterior\n",
        "#         en1 = F.softplus(self.en1_fc(input_))                           # en1_fc   output\n",
        "#         en2 = F.softplus(self.en2_fc(en1))                              # encoder2 output\n",
        "#         en2 = self.en2_drop(en2)\n",
        "#         posterior_mean   = self.mean_bn  (self.mean_fc  (en2))          # posterior mean\n",
        "#         posterior_logvar = self.logvar_bn(self.logvar_fc(en2))          # posterior log variance\n",
        "#         posterior_var    = posterior_logvar.exp()\n",
        "\n",
        "#         return en2, posterior_mean, posterior_logvar, posterior_var\n",
        "\n",
        "#     def take_sample(self, input_, posterior_mean, posterior_var, prior_var):\n",
        "#         # take sample\n",
        "#         eps = input_.data.new().resize_as_(posterior_mean.data).normal_(std=1) # noise\n",
        "#         # N x X\n",
        "#         z = posterior_mean + posterior_var.sqrt() * eps                   # reparameterization\n",
        "\n",
        "#         return z\n",
        "\n",
        "#     def decode(self, z):\n",
        "#         # decode\n",
        "#         N, *_ = z.size()\n",
        "#         zx = self.decoder_x_bn(z).view(N, 1, self.num_coordinate) # Nx1xX\n",
        "\n",
        "#         # se = self.decoder_x_bn(z).view(N, S, self.num_coordinate) # NxSxV\n",
        "\n",
        "#         # zx = z.view(N, 1, self.num_coordinate) # Nx1xX\n",
        "\n",
        "#         size = (N, self.out_features, self.in_features) # N,K,2\n",
        "#         x = zx.expand(size)\n",
        "#         c = self.decoder_phi_bn(self.centres).unsqueeze(0).expand(size)\n",
        "#         # c = self.centres.unsqueeze(0).expand(size)\n",
        "\n",
        "#         d = (x-c).pow(2).sum(-1)\n",
        "#         distances = self.basis_func(d) #NxK\n",
        "#         zx_phi = torch.exp(distances - torch.logsumexp(distances, dim=-1, keepdim=True))\n",
        "\n",
        "#         ##############\n",
        "#         c_norm = self.decoder_phi_bn(self.centres).pow(2).sum(-1).unsqueeze(-1)\n",
        "#         R_phi = torch.exp(-0.5 * c_norm/mu_div)\n",
        "#         input_sq = input_.unsqueeze(3).expand(256,50,5000,20)\n",
        "#         ##############\n",
        "\n",
        "#         recon_v = torch.mm(zx_phi, F.softmax(self.decoder_bn(self.decoder.weight).transpose(1,0), dim=-1))\n",
        "#         return recon_v, zx, zx_phi, d, c\n",
        "\n",
        "#     def forward(self, input_, relevant_scores, gpu_n_s_v, compute_loss=False):\n",
        "#         en2, posterior_mean, posterior_logvar, posterior_var = self.encode(input_)\n",
        "#         z = self.take_sample(input_, posterior_mean, posterior_var, self.variance_x)\n",
        "\n",
        "#         # decode\n",
        "#         recon_v, zx, zx_phi,d,c= self.decode(z)\n",
        "\n",
        "#         if compute_loss:\n",
        "#             return recon_v, self.loss(input_, recon_v, zx_phi, posterior_mean, posterior_logvar, posterior_var, d, c, relevant_scores, zx, gpu_n_s_v)\n",
        "#         else:\n",
        "#             return z, recon_v, zx, zx_phi\n",
        "\n",
        "\n",
        "#     def loss(self, input_, recon_v, zx_phi, posterior_mean, posterior_logvar, posterior_var, d, c, relevant_scores, zx, gpu_n_s_v, avg=True):\n",
        "\n",
        "#         N = posterior_mean.shape[0]\n",
        "#         L = recon_v.shape[0]\n",
        "#         NL = - (input_ * (recon_v+1e-10).log()).sum(-1)\n",
        "\n",
        "# #         N1, *_ = z.size()\n",
        "# #         size = (N1, self.out_features, self.in_features)\n",
        "# #         c = self.decoder_phi_bn(self.centres).unsqueeze(0).expand(size)\n",
        "\n",
        "#         prior_mean   = self.prior_mean.expand_as(posterior_mean)\n",
        "#         prior_var    = self.prior_var.expand_as(posterior_mean)\n",
        "#         prior_logvar = self.prior_logvar.expand_as(posterior_mean)\n",
        "\n",
        "#         var_division    = posterior_var  / prior_var #Nx2\n",
        "#         diff            = posterior_mean - prior_mean\n",
        "#         diff_term       = diff * diff / prior_var\n",
        "#         logvar_division = prior_logvar - posterior_logvar\n",
        "\n",
        "#         xKLD = 0.5 * ( (var_division + diff_term + logvar_division).sum(-1) - self.num_coordinate)\n",
        "#         return_xKLD = xKLD.mean(0)\n",
        "#         KL = return_xKLD\n",
        "\n",
        "#         # NegativeLogL_RScore = - LogL_Score_beta(zx_phi,self.decoder_phi_bn(self.centres),relevant_scores)\n",
        "#         # NegativeLogL_RScore = - LogL_Score(zx,relevant_scores)\n",
        "#         # x_norm = torch.norm(zx,dim=-1)\n",
        "#         # NegativeLogL_RScore = (100000 * (torch.exp(-0.5 * (torch.pow(x_norm,2)/10.0) - relevant_scores )  )**2  ).sum()\n",
        "#         # NegativeLogL_RScore = LogL_Score_test(zx,relevant_scores)\n",
        "\n",
        "#         #NegativeLogL_RScore = - LogL_Score_TND(zx_phi,self.decoder_phi_bn(self.centres),relevant_scores, self.query_center,zx)\n",
        "\n",
        "#         #NegativeLogL_RScore = - LogL_gaussianScore(zx,relevant_scores,self.query_center)\n",
        "#         # Final Function\n",
        "\n",
        "#         NegativeLogL_RScore = - torch.log(sum(R * Z * (W^input_w).prod())).sum()\n",
        "\n",
        "#         #loss = NL.sum() + KL + NegativeLogL_RScore\n",
        "#         loss = NL.sum() + KL\n",
        "\n",
        "#         # print(type(loss))\n",
        "#         return loss/N, NL.sum(), return_xKLD,  KL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFRHWpuwBmWn"
      },
      "source": [
        "# Extra (WordCloud, Archive TFIDF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_6ifWD8l8WA"
      },
      "source": [
        "WordCloud\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8Q7B-0Apmz0"
      },
      "source": [
        "!pip install wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KNJAR_ifvVv"
      },
      "source": [
        "word_list=data_20news_preprocessed[j].split()\n",
        "print(word_list)\n",
        "flatten_all_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-0-_FjTptoz"
      },
      "source": [
        "import pandas as pd\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "comment_words = ''\n",
        "topic_topword_comment = ''\n",
        "\n",
        "for val in top_10_docs:\n",
        "    comment_words += \" \".join(val)+\" \"\n",
        "\n",
        "for topword_topic in topword_topics_list:\n",
        "    topic_topword_comment += \" \".join(topword_topic)+\" \"\n",
        "\n",
        "wordcloud_top10_docs = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(comment_words)\n",
        "\n",
        "wordcloud_topword_topics = WordCloud(width = 800, height = 800,\n",
        "                background_color ='white',\n",
        "                stopwords = stopwords,\n",
        "                min_font_size = 10).generate(topic_topword_comment)\n",
        "\n",
        "f = plt.figure(1,figsize = (8, 8))\n",
        "plt.title('Words in Top Relevant 10 Docs')\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 3.0)\n",
        "plt.imshow(wordcloud_top10_docs)\n",
        "g = plt.figure(2,figsize = (8, 8))\n",
        "plt.title(\"Top Words in k topics\")\n",
        "plt.axis(\"off\")\n",
        "plt.tight_layout(pad = 3.0)\n",
        "plt.imshow(wordcloud_topword_topics)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2p5lYecYtWFm"
      },
      "source": [
        "Archive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK6dBYHd4BnC"
      },
      "source": [
        "import plotly.graph_objects as go\n",
        "epochs=1000\n",
        "def plot_loss(y,name):\n",
        "  figure = go.Figure()\n",
        "  figure.add_trace(go.Scatter(x=[i for i in range(1,epochs+1)], y=y,mode='lines',name=name))\n",
        "  figure.show(renderer='colab')\n",
        "\n",
        "plot_loss(x_arr,'KLD')\n",
        "plot_loss(recon_arr,'Recon_loss')\n",
        "plot_loss(neg_log_rscore_arr,'RScore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSN6RiXaXiYq"
      },
      "source": [
        "plt.hist(x=all_rscores.data)\n",
        "\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "normalized_all_rscores = scaler.fit_transform(all_rscores.data.reshape(-1,1))\n",
        "normalized_all_rscores"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIKqMyokYnQG"
      },
      "source": [
        "plt.hist(x=normalized_all_rscores)\n",
        "# print(normalized_all_rscores)\n",
        "np.max(normalized_all_rscores.flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zyt072hYrLe9"
      },
      "source": [
        "# with open('neg_log_rscore_arr.txt', 'w') as filehandle:\n",
        "#     for listitem in neg_log_rscore_arr:\n",
        "#         filehandle.write('%s\\n' % listitem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rbbelM5O9vj"
      },
      "source": [
        "all_words_in_docs=[]\n",
        "\n",
        "def doc_to_words(doc):\n",
        "  word_list=[]\n",
        "  for i in doc:\n",
        "    words = i.split()\n",
        "    word_list.append([w for w in words])\n",
        "  return word_list\n",
        "\n",
        "all_words_in_docs = doc_to_words(data_WoS_preprocessed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gu_wcnuhQ3y2"
      },
      "source": [
        "# data_20news_embedded = []\n",
        "# for word in all_words_in_docs:\n",
        "#   for w in word:\n",
        "#     try:\n",
        "#       type(word2vec_model[w])=='numpy.ndarray'\n",
        "#     except KeyError:\n",
        "#       word.remove(w)\n",
        "#   data_20news_embedded.append(' '.join(word))\n",
        "# # data_20news_embedded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgww2GGBQxlb"
      },
      "source": [
        "def flatten_list(user_list):\n",
        "  return [item for sublist in user_list for item in sublist]\n",
        "flatten_all_words = flatten_list(all_words_in_docs)\n",
        "# # flatten_embedded = flatten_list(data_20news_embedded)\n",
        "# # flatten_embedded"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPpZcOA5R_FI"
      },
      "source": [
        "# len(set(flatten_all_words))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqoR2yotPR0y"
      },
      "source": [
        "count=0\n",
        "embeddings = {}\n",
        "\n",
        "for f in flatten_all_words:\n",
        "  try :\n",
        "     embeddings[f] = word2vec_model[f]\n",
        "  except KeyError:\n",
        "    count = count+1\n",
        "print( count / len(flatten_all_words)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmaScPcQ8fFW"
      },
      "source": [
        "save_obj(embeddings,'embeddings_WoS')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7aT_AcryygB"
      },
      "source": [
        "> Keyword search in corpus: Returns docs with matching keywords\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yotYgCXX0s96"
      },
      "source": [
        "matching = [s for s in data_20news_preprocessed if \" sport \" in s]\n",
        "matching"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFiMVsBNmeXC"
      },
      "source": [
        "# !wget https://www.dropbox.com/s/yg1zf6hel0zxt3i/data_20news_preprocessed_labels.pkl\n",
        "# !wget https://www.dropbox.com/s/5drfxhzxz8nsy2l/embeddings_20news.pkl\n",
        "# !wget https://www.dropbox.com/s/756dcuil3mjdgus/data_20news_preprocessed.pkl"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dk4oWni-BmyK"
      },
      "source": [
        "TFIDF"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cn3LWv9teLx"
      },
      "source": [
        "def cosine_similarity_desm_docs_tfidf(query_list, doc, embeddings):\n",
        "\n",
        "  sim_list = torch.zeros(len(doc))\n",
        "  index = 0\n",
        "\n",
        "  for d in doc:\n",
        "    doc_bar = torch.zeros(300)\n",
        "    words = d.split()\n",
        "    for word in words:\n",
        "      doc_bar.add_(torch.from_numpy(embeddings[word])/torch.norm(torch.from_numpy(embeddings[word])))\n",
        "    doc_bar = doc_bar / len(words)\n",
        "    sum = 0\n",
        "\n",
        "    for q in query_list:\n",
        "      sum += torch.dot(torch.from_numpy(embeddings[q]) , doc_bar)/(torch.norm(torch.from_numpy(embeddings[q]))*torch.norm(doc_bar))\n",
        "    sum = sum/len(query_list)\n",
        "    sim_list[index]=sum\n",
        "    index = index + 1\n",
        "\n",
        "  return sim_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o96bc037wCXv"
      },
      "source": [
        "tfidfvectorizer = TfidfVectorizer(min_df=5,dtype=np.float32,use_idf=True)\n",
        "tfIdf = tfidfvectorizer.fit_transform(data_preprocessed)\n",
        "df_tfidf = pd.DataFrame(tfIdf[0].T.todense(), index=tfidfvectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
        "# df_tfidf = df_tfidf.sort_values('TF-IDF', ascending=False)\n",
        "df_tfidf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSxjafLpVnPz"
      },
      "source": [
        "list(vocab.values())[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OA8tbyvV-3E"
      },
      "source": [
        "df_tfidf[]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwVGOvzM93yh"
      },
      "source": [
        "df_doc_term_matrix = pd.DataFrame(tfIdf.toarray().transpose(),index=tfidfvectorizer.get_feature_names())\n",
        "df_doc_term_matrix_sum = df_doc_term_matrix.sum(axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xWNkoElfS0Xc"
      },
      "source": [
        "df_doc_term_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8O9PBVI-k_u"
      },
      "source": [
        "df_doc_term_matrix_sum.sort_values(ascending=True)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}